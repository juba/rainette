---
title: "[fr] Utilisation de rainette"
author: "Julien Barnier"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{[fr] Utilisation de rainette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---



# Installation

Le *package* n'étant pas encore disponible sur le CRAN, il s'installe depuis GitHub *via* l'extension `remotes` :

```{r eval=FALSE}
remotes::install_github("juba/rainette")
```


# Préparation du corpus

## Importation

La première étape consiste à importer votre corpus dans R. Vous pouvez utiliser un corpus au format `tm` ou `quanteda` par exemple, ou bien utiliser la fonction `import_corpus_iramuteq` pour importer directement un corpus depuis un fichier texte [au format Iramuteq](http://www.iramuteq.org/documentation/formatage-des-corpus-texte). Dans ce cas vous obtiendrez un objet de type corpus du package [quanteda](https://quanteda.io). Les métadonnées éventuelles présentes dans le fichier (*variables étoilées*) sont importées en tant que métadonnées du corpus (variables de `docvars(corpus)`).

Pour ce document, on va importer le texte du *Manifeste du parti communiste* (Karl Marx et Friedrich Engels, 1848, source [wikisource](https://fr.wikisource.org/wiki/Manifeste_du_parti_communiste/Lafargue)). Celui-ci est placé dans un fichier texte au format Iramuteq fourni avec `rainette`. Le corpus est composé de quatre documents, un document par partie de l'ouvrage.

```{r message=FALSE}
library(rainette)
library(quanteda)
## Import du corpus
fichier <- system.file("extdata", "manifeste_pc.txt", package = "rainette")
corpus <- import_corpus_iramuteq(fichier)
```

On peut vérifier que notre corpus est bien constitué de 4 documents (l'introduction et les trois parties principales), et d'une variable de métadonnée :

```{r}
corpus
```

Cette variable de métadonnée est justement la partie correspondant au texte :

```{r paged.print=TRUE}
docvars(corpus)
```


## Découpage en segments

La méthode Reinert de classification s'applique en général à des segments de texte relativement courts (appelés *uce*, unités de contexte élémentaires), et non à des textes longs. Une première étape consiste donc à découper chaque texte du corpus en segments via la fonction `split_segments`. Ici on découpe en segments d'environ 40 mots (l'algorithme essaie de tenir compte de la ponctuation pour, par exemple, placer les césures entre des phrases ou au niveau d'une virgule).

```{r message=FALSE}
corpus <- split_segments(corpus, segment_size = 40)
```

Notre corpus est désormais constitué de 318 segments et 2 variables de métadonnées :

```{r}
corpus
```

Si on regarde les nouvelles métadonnées, on peut voir que la variable `partie` a été dupliquée pour chaque segment correspondant, et une nouvelle variable `segment_source` indique le document d'origine du segment.

```{r}
head(docvars(corpus))
```

On peut aussi visualiser les premiers segments de texte calculés :

```{r}
as.character(corpus)[1:2]
```


## Calcul et traitement de la matrice termes-documents

L'étape suivante est de calculer la matrice termes-documents (*dtm*), grand tableau numérique avec les documents en lignes, les mots en colonnes, et le nombre d'occurrences de chaque mot dans chaque document comme valeurs.

Notre corpus étant au format `quanteda`, on va utiliser les fonction de cette extension.

D'abord on calcule la *dtm* en convertissant le texte en minuscules, et en supprimant ponctuation, nombres, et les mots-outils français les plus courants :

```{r}
dtm <- dfm(corpus, remove = stopwords("fr"), tolower = TRUE, remove_punct = TRUE, remove_numbers = TRUE)
```

On va ensuite procéder à la racinisation des termes, puis on va supprimer les termes apparaissant dans moins de 3 segments :

```{r}
dtm <- dfm_wordstem(dtm, language = "french")
dtm <- dfm_trim(dtm, min_termfreq = 3)
```

De nombreux autres traitements seraient possibles ou préférables, mais on se contentera de cette matrice pour cet exemple.


# Classification simple

Une fois notre matrice prête, on peut procéder à une première forme de classification : une classification descendante hiérarchique simple, calculée avec la fonction `rainette`. Ici on va lui passer plusiurs arguments : le nombre maximal de classes souhaitées (`k = 5`) et le nombre minimal de termes pour qu'une classe soit découpée en deux à l'étape suivante de la classification (`min_split_members = 10`).

L'argument `min_uc_size`, lui, indique le nombre minimal de mots par segment. En effet, lors du calcul de la dtm, certaines formes (mots-outils, mots trop peu fréquents) ont été supprimées, nos segments peuvent donc varier en taille (entendue comme le nombre de mots encore présents). Avec `min_uc_size = 10`, les segments comportant moins de 10 formes sont regroupés avec le segment suivant jusqu'à atteindre la taille minimale souhaitée.

```{r message=FALSE}
res <- rainette(dtm, k = 5, min_uc_size = 10, min_split_members = 10)
```

L'objet résultat ne nous dit pas grand chose en lui-même :

```{r}
res
```

Pour faciliter l'exploration des résultats, `rainette` propose une interface interactive sous la forme d'un *gadget shiny*, qui peut être lancée avec la fonction `rainette_explor` :

```{r eval = FALSE}
rainette_explor(res, dtm)
```

L'interface devrait ressembler à quelque chose comme ça :

![](rainette_explor_pc.png)

Vous pouvez modifier le nombre de classes, la statistique utilisée pour le calcul des termes caractéristiques, etc. Par défaut, les graphiques sous chaque classe vous indiquent les termes les plus caractéristiques du groupe positivement (en bleu) ou négativement (en rouge) selon la statistique considérée.

À noter que vous pouvez aussi opter pour des graphiques sous forme de nuages de mots :

![](rainette_explor_pc_cloud.png)

Cette interface vous permet d'expérimenter librement sur le nombre de classes et leur interprétation. Vous pouvez à tout moment cliquer sur le bouton *Get R code* pour obtenir le code R correspondant au graphique actuellement affiché, ainsi que la commande `cutree_rainette` qui vous permet de récupérer les groupes d'appartenance de chaque document du corpus, là aussi selon le nombre de groupes actuellement affichés.

```{r eval=FALSE}
## Clustering description plot
rainette_plot(res, dtm, k = 5, type = "bar", n_terms = 20, free_scales = FALSE,
    measure = "chi2", show_negative = "TRUE", text_size = 11)
## Groups
cutree_rainette(res, k = 5)
```

Vous pouvez par exemple utiliser l'appel de `cutree_rainette` pour ajouter comme nouvelle métadonnée du corpus le groupe d'appartenance pour la classification en 5 classes :

```{r}
corpus$group <- cutree_rainette(res, k = 5)
head(docvars(corpus))
```

Vous pouvez aussi récupérer directement les statistiques de spécificité de chaque groupe à l'aide de `rainette_stats` :

```{r}
rainette_stats(corpus$group, dtm, n_terms = 5)
```



# Classification double

Le deuxième type de classification proposé est une classification double : selon la méthode proposée par Max Reinert, on effectue deux classifications simples en faisant varier la taille minimale des segments, puis on "croise" les résultats de ces deux classifications pour déterminer de nouvelles classes, potentiellement plus robustes.

Une classification double utilise la fonction `rainette2`. Celle-ci peut se faire de deux manières. On peut d'abord effectuer les deux classifications simples, ici une avec une taille de segment minimale à 10, et une autre à 15 :

```{r message=FALSE}
res1 <- rainette(dtm, k = 7, min_uc_size = 10, min_split_members = 10)
res2 <- rainette(dtm, k = 7, min_uc_size = 15, min_split_members = 10)
```

Puis on utilise `rainette2` sur ces deux objets résultats, en lui indiquant le nombre maximal de classes à calculer (argument `max_k`) et le nombre minimal de segments par classe (argument `min_members`) :

```{r message=FALSE}
res <- rainette2(res1, res2, max_k = 7, min_members = 10)
```

L'autre manière est d'appeler directement `rainette2` sur notre matrice dtm, en lui indiquant avec les arguments `uc_size1` et `uc_size2` les deux tailles de segments souhaitées :

```{r eval=FALSE}
res <- rainette2(dtm, uc_size1 = 10, uc_size2 = 15, max_k = 7, min_members = 10)
```

L'objet résultat est un *tibble* contenant, pour chaque valeur de `k`, les partitions optimales trouvées et leurs caractéristiques. Là encore, une interface interactive est proposée pour visualiser et explorer ces résultats. Elle se lance via la fonction `rainette2_explor` :

```{r eval=FALSE}
rainette2_explor(res, dtm)
```

![](rainette2_explor.png)
L'interface est très semblable à la précédente, sauf qu'il n'y a plus de dendrogramme mais à la place un diagramme en barre des effectifs des groupes. Soyez attentifs aux `NA`, qui représentent les segments non classés : contrairement à la classification simple, ils peuvent être assez nombreux ici.

Là encore, vous pouvez utiliser le bouton *Get R code* pour récupérer et copier/coller le code R permettant de reproduire le graphique affiché, et récupérer les groupes d'appartenance des segments du corpus.

Vous pouvez également utiliser `rainette_stats` pour récupérer les statistiques de spécificité des groupes :

```{r}
groups <- cutree(res, 3)
rainette_stats(groups, dtm, n_terms = 5)
```

Si certains points n'ont pas été affecté à un groupe, vous pouvez utiliser `rainette2_complete_groups` pour les assigner au groupe le plus proche selon une méthode _k-nearest neighbors_ :

```{r}
groups_completed <- rainette2_complete_groups(dtm, groups)
```


