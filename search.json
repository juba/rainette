[{"path":[]},{"path":"https://juba.github.io/rainette/articles/algorithmes.html","id":"matrice-de-départ","dir":"Articles","previous_headings":"Algorithme de classification simple","what":"Matrice de départ","title":"[fr] Description des algorithmes","text":"La classification simple est une classification descendante hiérarchique (CDH). Le tableau de départ est la matrice termes-documents croisant les documents du corpus et les termes qui les composent. Cette matrice est une matrice binaire de présence/absence du terme dans le document, et non une matrice d’occurrences. donc un tableau de ce type : À noter que si les documents sont des segments obtenus avec split_segments(), les segments trop courts d’un même document peuvent être regroupés entre eux au moment de la classification pour atteindre la taille minimale indiquée par l’argument min_segment_size de rainette().","code":"##      partir un jour sans retour ## doc1      1  1    0    1      0 ## doc2      0  1    1    0      1 ## doc3      1  1    1    0      1 ## doc4      0  1    0    1      1"},{"path":"https://juba.github.io/rainette/articles/algorithmes.html","id":"division-maximisant-le-khi2","dir":"Articles","previous_headings":"Algorithme de classification simple","what":"Division maximisant le Khi2","title":"[fr] Description des algorithmes","text":"souhaite diviser cette matrice termes-documents en deux groupes de documents aussi “différents” que possible. La méthode Reinert consiste à sélectionner le regroupement qui maximise la statistique du χ² du tableau regroupé. Par exemple, dans le tableau ci-dessus, si regroupe doc1 avec doc2 et doc3 avec doc4, obtient le tableau suivant : peut calculer la valeur du χ² de ce tableau. Cette statistique est un indicateur de la “distance” entre les deux groupes de documents en ce qui concerne la distribution des termes : plus la valeur du χ² du tableau regroupé est élevée et plus les deux groupes sont différents, plus elle est faible et plus ils se ressemblent. Dans un cas aussi simple, peut effectuer tous les regroupements de documents possibles et déterminer lequel correspond au χ² maximal, mais avec des données réelles la complexité augmente trop rapidement. opère donc de la manière suivante : effectue une analyse factorielle des correspondances de la matrice termes-documents, et ordonne les documents selon leur coordonnée sur le premier axe de cette AFC. regroupe tour à tour les documents entre eux selon cet ordonnancement : d’abord le point avec la coordonnée la plus basse vs tous les autres, puis les deux points avec les coordonnées les plus basses vs tous les autres, etc. calcule à chaque fois le χ² correspondant et conserve au final le regroupement qui le maximise. à partir de ce regroupement, effectue une réaffectation des documents : change tour à tour chaque document de classe, et regarde si cela fait augmenter le χ². Si c’est le cas conserve cette nouvelle affectation. recommence cette opération de réaffectation jusqu’à ce qu’elle ne permette plus d’augmenter la valeur du χ². obtient donc au final deux groupes de documents et deux matrices termes-documents correspondantes.","code":"##             partir un jour sans retour ## doc1 + doc2      1  2    1    1      1 ## doc3 + doc4      1  2    1    1      2"},{"path":"https://juba.github.io/rainette/articles/algorithmes.html","id":"sélection-des-termes","dir":"Articles","previous_headings":"Algorithme de classification simple","what":"Sélection des termes","title":"[fr] Description des algorithmes","text":"L’étape suivante consiste en une sélection des termes dans chacun des deux tableaux pour les prochaines itérations : regarde la fréquence de chaque terme, et supprime les termes qui apparaissent moins de 3 fois (cette valeur est modifiable via l’argument tsj de rainette()). compare également l’effectif observé de chaque terme avec l’effectif attendu sous l’hypothèse d’indépendance de la répartition du terme entre les deux groupes, et en déduit un coefficient de contingence pour ce terme. Si ce coefficient de contingence est supérieur à 0.3, ne conserve le terme que dans le tableau dans lequel il est surreprésenté (le seuil de 0.3 est modifiable via l’argument cc_test de rainette()).","code":""},{"path":"https://juba.github.io/rainette/articles/algorithmes.html","id":"classification-descendante-hiérarchique","dir":"Articles","previous_headings":"Algorithme de classification simple","what":"Classification descendante hiérarchique","title":"[fr] Description des algorithmes","text":"Les étapes précédentes permettent de scinder un corpus en deux groupes. Pour obtenir une hiérarchie de classes, commence par scinder le corpus entier, puis recommence de la même manière avec le groupe obtenu comportant le plus de documents (sauf si le tableau en question est trop petit pour calculer une AFC, ou si son effectif est inférieur à l’argument min_split_members de rainette()). En procédant de cette manière k - 1 fois, obtient une classification descendante hiérarchique (CDH) en k groupes, et le dendrogramme correspondant (la hauteur des branches du dendrogramme étant la valeur maximale du χ² trouvée au moment du split).","code":""},{"path":"https://juba.github.io/rainette/articles/algorithmes.html","id":"algorithme-de-classification-double","dir":"Articles","previous_headings":"","what":"Algorithme de classification double","title":"[fr] Description des algorithmes","text":"La classification double s’applique à un corpus découpé en segments. L’objectif est d’obtenir des classes plus robustes en croisant les résultats de deux classifications simples calculées avec des tailles minimales de segments différentes. La classification double consiste donc à effectuer deux classifications simples avec des valeurs distinctes de min_segment_size. obtient donc deux dendrogrammes différents qui déterminent des classes ici numérotées de 1 à 6 :","code":""},{"path":"https://juba.github.io/rainette/articles/algorithmes.html","id":"calcul-des-classes-croisées","dir":"Articles","previous_headings":"Algorithme de classification double","what":"Calcul des classes croisées","title":"[fr] Description des algorithmes","text":"La première étape consiste à croiser les classes des deux CDH :  prend chaque classe de la première CDH, et la croise avec chaque classe de la seconde (y compris si les classes ne sont pas de même niveau k). appelle la nouvelle classe obtenue une “classe croisée” : pour chaque classe croisée, calcule l’effectif du croisement, c’est à dire le nombre de documents présents dans les deux classes. à partir de cet effectif, de l’effectif de chaque classe et du nombre total de documents, peut créer un tableau croisé d’appartenance aux deux classes : calcule alors le χ² de ce tableau, qui représente une mesure de “l’association” entre les deux classes. si deux classes croisées différentes comportent les mêmes documents, ne conserve que l’une d’entre elles. si une classe croisée comporte un effectif inférieur à la valeur de l’argument min_members de rainette2(), elle n’est pas conservée. si une classe croisée comporte un χ² d’association inférieur à la valeur de l’argument min_chi2 de rainette2(), elle n’est pas conservée. Une fois ces classes croisées définies, deux type d’analyse sont possibles.","code":""},{"path":"https://juba.github.io/rainette/articles/algorithmes.html","id":"analyse-full","dir":"Articles","previous_headings":"Algorithme de classification double > Calcul des classes croisées","what":"Analyse “full”","title":"[fr] Description des algorithmes","text":"La première, dite analyse “full” (argument full = TRUE de rainette2()), conserve pour la suite toutes les classes croisées dont l’effectif est supérieur à zéro (si celles-ci n’ont pas déjà été filtrées à l’étape précédente). Dans l’exemple ci-dessus, conserverait donc :","code":""},{"path":"https://juba.github.io/rainette/articles/algorithmes.html","id":"analyse-classique","dir":"Articles","previous_headings":"Algorithme de classification double > Calcul des classes croisées","what":"Analyse “classique”","title":"[fr] Description des algorithmes","text":"La seconde, dite analyse “classique” (argument full = FALSE de rainette2()) ne conserve une classes croisée que si les deux groupes croisés sont mutuellement les plus associés. Ainsi, si considère la classe croisée issue du croisement du groupe x et du groupe y, ne conserve cette classe que si y est le groupe ayant le χ² d’association maximal avec x, et si en même temps x est le groupe ayant le χ² d’association maximal avec y. Dans ce cas le nombre de classes croisées considérées est beaucoup plus réduit :","code":""},{"path":"https://juba.github.io/rainette/articles/algorithmes.html","id":"calcul-et-sélection-des-partitions-optimales","dir":"Articles","previous_headings":"Algorithme de classification double","what":"Calcul et sélection des partitions optimales","title":"[fr] Description des algorithmes","text":"L’étape suivante consiste à déterminer, à partir des classes croisées calculées précédemment, toutes les partitions possibles de nos documents en 2, 3, 4… classes croisées. Plus précisément, essaie de déterminer tous les groupes de 2, 3, 4… classes croisées qui n’ont aucun élément en commun. commence par déterminer les partitions de taille 2, c’est-à-dire tous les ensembles de deux classes croisées n’ayant aucun élément commun. calcule pour chaque partition son effectif total et la somme de ses χ² d’association. sélectionne parmi ces partitions celles qui sont considérées comme les “meilleures”, c’est-à-dire : si fait une analyse “full” (full = TRUE), sélectionne celle ayant la somme de χ² d’association la plus forte, et celle ayant l’effectif total le plus élevé. si fait une analyse “classique” (full = FALSE), sélectionne uniquement celle ayant la somme de χ² d’association la plus forte (ne peut pas utiliser l’effectif total comme critère de sélection dans ce cas-là). fait de même pour les partitions de taille 3 : détermine les différentes partitions possibles et conserve les meilleures. Et continue pour les partitions de 4 classes croisées, etc. répète l’opération jusqu’à atteindre la valeur de l’argument max_k de rainette2(), ou bien lorsqu’il n’y aucune partition possible au niveau considéré.","code":""},{"path":"https://juba.github.io/rainette/articles/algorithmes.html","id":"résultat","dir":"Articles","previous_headings":"Algorithme de classification double","what":"Résultat","title":"[fr] Description des algorithmes","text":"obtient donc au final, pour chaque valeur de k de 2 à max_k, une sélection de partitions de classes croisées considérées comme “optimales”, soit selon le critère de la somme de leur χ² d’association, soit selon celui de leur effectif total. Ces classes croisées constituent de nouveaux groupes potentiellement plus “robustes” que ceux mis en évidence par les deux CDH simples. À noter que cette opération peut faire qu’un grand nombre de documents n’appartiennent à aucun des nouveaux groupes. rainette propose de réaffecter ces documents aux nouveaux groupes via une méthode rapide de type k-nearest neighbours, mais ceci n’est pas forcément conseillé dans la mesure où perdrait la “robustesse” qui est justement l’objectif de la double classification.","code":""},{"path":[]},{"path":"https://juba.github.io/rainette/articles/algorithmes.html","id":"classification-simple","dir":"Articles","previous_headings":"Différences avec Iramuteq","what":"Classification simple","title":"[fr] Description des algorithmes","text":"L’implémentation de l’algorithme dans rainette se différencie de celle d’Iramuteq surtout dans la gestion du paramètre min_split_members (le nombre minimal de documents dans une classe). Dans rainette, min_split_members est uniquement utilisé au moment du choix du tableau suivant à splitter : si aucun tableau n’un effectif supérieur à ce paramètre, l’algorithme s’arrête même si n’pas atteint la valeur souhaitée de k. Dans Iramuteq, l’algorithme se répète k fois dans tous les cas, et il procède à la fin à un regroupement des classes dont l’effectif est inférieur à l’effectif minimal souhaité. Ce regroupement s’effectue en fusionnant ces classes en “remontant” le dendrogramme. L’avantage de l’implémentation dans rainette est qu’ne “casse” pas la logique du dendrogramme, et qu’obtient donc comme résultat un arbre complet, qu’peut couper à la hauteur souhaitée : peut donc explorer la classification en 2, 3 … k groupes. L’inconvénient est qu’n’pas d’assurance de n’avoir aucune classe avec un effectif inférieur à min_split_members : doit procéder à des regroupements manuels si nécessaire.","code":""},{"path":"https://juba.github.io/rainette/articles/algorithmes.html","id":"classification-double","dir":"Articles","previous_headings":"Différences avec Iramuteq","what":"Classification double","title":"[fr] Description des algorithmes","text":"La méthode proposée par Iramuteq correspond plutôt à la méthode “full” de ce document : après avoir déterminé les classes croisées, conserve toutes celles ayant un effectif et une valeur de χ² d’association suffisants. L’algorithme reste très proche de celui d’Iramuteq jusqu’à l’étape de la sélection de partition optimale. Ici procède à une recherche exhaustive des partitions à partir des classes croisées sélectionnées (ce qui peut occasionner des calculs potentiellement très longs si min_members est faible et max_k élevé), tandis qu’Iramuteq procède autrement. Au niveau des résultats, Iramuteq ne renvoie qu’une seule partition qu’il juge optimale, tandis que rainette retourne pour chaque valeur de k les meilleures partitions selon les critères de la taille ou du χ² maximum.","code":""},{"path":"https://juba.github.io/rainette/articles/algorithmes.html","id":"différences-avec-la-méthode-reinert","dir":"Articles","previous_headings":"","what":"Différences avec la “méthode Reinert”","title":"[fr] Description des algorithmes","text":"Le mode de détermination des partitions optimales ne nous pas semblé très détaillé dans les articles cités en références, il ne nous est donc pas vraiment possible de comparer avec l’implémentation de rainette. priori la méthode présentée par Max Reinert correspond à la méthode dite “classique” présentée dans ce document : après le calcul des classes croisées ne conserve que celles dont les deux groupes croisés sont les plus associés mutuellement. Une différence importante réside dans le fait que dans les articles cités, une fois la partition optimale déterminée, celle-ci est utilisée comme point de départ pour une affectation des documents aux classes via une méthode de type “nuées dynamiques”. Ceci permet notamment de réaffecter des points qui ne feraient pas partie des classes croisées de la partition retenue. Cette réaffectation par centre mobile n’est pas implémentée dans rainette (et elle ne semble pas l’être non plus dans Iramuteq). Il faut donc être vigilant au nombre et à la proportion de documents non affectés (valeur de classe à NA) à l’issue d’une classification double, car celui-ci peut être élevé. Une fonction rainette2_complete_groups() est disponible pour rattacher les points non affectés à une des classes via une méthode du type k-nearest neighbours, mais son utilisation n’est pas forcément conseillée.","code":""},{"path":"https://juba.github.io/rainette/articles/algorithmes.html","id":"références","dir":"Articles","previous_headings":"","what":"Références","title":"[fr] Description des algorithmes","text":"Reinert M., “Une méthode de classification descendante hiérarchique : application à l’analyse lexicale par contexte”, Cahiers de l’analyse des données, Volume 8, Numéro 2, 1983. http://www.numdam.org/item/?id=CAD_1983__8_2_187_0 Reinert M., “Alceste une méthodologie d’analyse des données textuelles et une application: Aurelia De Gerard De Nerval”, Bulletin de Méthodologie Sociologique, Volume 26, Numéro 1, 1990. https://doi.org/10.1177/075910639002600103 Reinert M., “Une méthode de classification des énoncés d’un corpus présentée à l’aide d’une application”, Les cahiers de l’analyse des données, Tome 15, Numéro 1, 1990. http://www.numdam.org/item/?id=CAD_1990__15_1_21_0","code":""},{"path":[]},{"path":"https://juba.github.io/rainette/articles/algorithms_en.html","id":"document-term-matrix","dir":"Articles","previous_headings":"Simple clustering algorithm","what":"Document-term matrix","title":"[en] Algorithms description","text":"simple clustering method divisive hierarchical clustering applied document-term matrix. matrix binary weighted, absence presence term document taken account. sample matrix : Note documents segments computed split_segments(), segments source may merged together clustering computation short don’t reach minimum size given min_segment_size argument rainette().","code":"##      return of the obra dinn ## doc1      1  1   1    1    1 ## doc2      0  0   1    1    1 ## doc3      1  1   1    0    0 ## doc4      0  1   0    0    0"},{"path":"https://juba.github.io/rainette/articles/algorithms_en.html","id":"maximal-χ²-splitting","dir":"Articles","previous_headings":"Simple clustering algorithm","what":"Maximal χ² splitting","title":"[en] Algorithms description","text":"newt step, goal split document-term matrix two groups documents “different” possible. Reinert method, “best” split one maximizes χ² value grouped array. example, using previous matrix, group together doc1 doc2 doc3 doc4, get following grouped array : can compute χ² statistics array, can seen association coefficient two document groups regarding term distributions : χ² high, two groups different, low can considered similar. simple case, compute every possible groupings determine one corresponds maximal χ² value, real data complexity needed computations rise rapidly. Reinert method therefore proceeds following way : first compute correspondance analysis document-term matrix, sort documents along coordinate first axis. group documents together successively following ordering : first lowest coordinate document vs others, two lowest ones vs others, . time compute χ² value grouped matrix, keep grouping corresponds highest χ² value. based grouping, succesively assign document group, see makes χ² rise. case, document kept group. operation repeated reassignment makes χ² higher. end get two groups documents two corresponding document-term matrices.","code":"##             return of the obra dinn ## doc1 + doc2      1  1   2    2    2 ## doc3 + doc4      1  2   1    0    0"},{"path":"https://juba.github.io/rainette/articles/algorithms_en.html","id":"terms-selection","dir":"Articles","previous_headings":"Simple clustering algorithm","what":"Terms selection","title":"[en] Algorithms description","text":"following step filter terms matrices next iteration : compute term frequency matrices, remove terms frequency lower 3 (value can changed using tsj argument rainette()). also compare observed frequency term expected frequency independance hypothesis distribution two groups. allows compute contingency coefficient : coefficient higher 0.3, term kept matrix overrepresented (0.3 threshold can changed using cc_test argument rainette()).","code":""},{"path":"https://juba.github.io/rainette/articles/algorithms_en.html","id":"divisive-hierarchical-clustering","dir":"Articles","previous_headings":"Simple clustering algorithm","what":"Divisive hierarchical clustering","title":"[en] Algorithms description","text":"previous steps allow split documents corpus two groups. get hierarchy groups, first split whole initial corpus, continue splitting biggest resulting cluster, ie one documents (unless cluster document-term matrix small compute correspondance analysis, size smaller value min_split_members argument rainette()). repeating k - 1 times, get divisive hierarchical clustering k clusters, corresponding dendrogram (height dendrogram branch given χ² value corresponding split).","code":""},{"path":"https://juba.github.io/rainette/articles/algorithms_en.html","id":"double-clustering-algorithm","dir":"Articles","previous_headings":"","what":"Double clustering algorithm","title":"[en] Algorithms description","text":"double clustering applies corpus split segments. goal make clusters robust crossing results two single clusterings computed different minimal segment sizes. double clustering implies therefore implies first two simple clusterings distinct min_segment_size values. get two different dendrograms determining different clusters, numbered 1 6 :","code":""},{"path":"https://juba.github.io/rainette/articles/algorithms_en.html","id":"cross-clusters-computation","dir":"Articles","previous_headings":"Double clustering algorithm","what":"Cross-clusters computation","title":"[en] Algorithms description","text":"first step algorithm cross clusters dendrograms together :  cluster first simple clustering crossed cluster second one, even cluster belong k level. new resulting cluster called “crossed cluster” : crossed cluster, compute size, ie number segments belonging clusters. using size, size clusters total number segments, can create cross table clusters membership : compute χ² value table, can seen “association coefficient” two clusters. two different crossed clusters hold exactly segments, keep one. crossed cluster size lower value min_members argument rainette2(), discarded. crossed cluster association χ² lower value min_chi2 argument rainette2(), discarded. crossed clusters computed, two types analysis possible.","code":""},{"path":"https://juba.github.io/rainette/articles/algorithms_en.html","id":"full-analysis","dir":"Articles","previous_headings":"Double clustering algorithm > Cross-clusters computation","what":"“full” analysis","title":"[en] Algorithms description","text":"first type, called “full” analysis (full = TRUE argument rainette2()), retains following steps crossed clusters size greater zero (already filtered previous step). previous example, keep :","code":""},{"path":"https://juba.github.io/rainette/articles/algorithms_en.html","id":"classical-analysis","dir":"Articles","previous_headings":"Double clustering algorithm > Cross-clusters computation","what":"“classical” analysis","title":"[en] Algorithms description","text":"second type, called “classical” analysis (full = FALSE argument rainette2()), keeps following steps crossed clusters whose clusters mutually associated. Thus, consider crossed cluster crossing cluster x cluster y, keep crossed cluster y cluster highest association χ² x, time x cluster highest association χ² y. case number crossed clusters kept following steps much lower :","code":""},{"path":"https://juba.github.io/rainette/articles/algorithms_en.html","id":"determining-optimal-partitions","dir":"Articles","previous_headings":"Double clustering algorithm","what":"Determining optimal partitions","title":"[en] Algorithms description","text":"goal next step identify, starting set crossed clusters defined previously, every possible partitions corpus 2, 3, 4… crossed clusters. precisely, try identify set 2, 3, 4… crossed clusters common elements. start computing size 2 partitions, ie every set 2 crossed clusters without common elements. partition compute total size sum association χ². keep among partitions ones considered “best” ones : “full” analysis (full = TRUE), keep one highest sum χ², one highest total size. “classical” analysis (full = FALSE), keep one highest sum χ² (can use highest total size criterion case). size 3 partitions : identify every set 3 non overlapping crossed clusters, keep “best” ones. repeat operation 4 crossed clusters, etc. operation repeated reach value max_k argument passed rainette2(), possible partition size k.","code":""},{"path":"https://juba.github.io/rainette/articles/algorithms_en.html","id":"result","dir":"Articles","previous_headings":"Double clustering algorithm","what":"Result","title":"[en] Algorithms description","text":"end get, k value 2 max_k, selection “best” crossed clusters partitions, either according association χ² criterion according total size criterion. crossed clusters form new set clusters potentially “robust” ones computed two simple clusterings. operation, potentially high number segments may belong cluster anymore. rainette allows reassign new clusters fast k-nearest neighbours method, may recommended loose clusters robustness acquired double clustering.","code":""},{"path":"https://juba.github.io/rainette/articles/algorithms_en.html","id":"differences-with-the-reinert-method","dir":"Articles","previous_headings":"","what":"Differences with the “Reinert method”","title":"[en] Algorithms description","text":"way determine optimal partitions seem completely clear us articles cited references, really possible compare rainette implementation. “classical” method described document seems close one suggested Max Reinert : computing crossed clusters, keep ones two crossed clusters mutually associated. One important difference fact best partition crossed clusters determined, Max Reinert suggests use new groups starting points reassign documents new clusters k-means type method. implemented rainette : rainette2_complete_groups() allows reassign documents without cluster using k-nearest neighbours method, may recommended want keep “robustness” clusters computed double clustering.","code":""},{"path":"https://juba.github.io/rainette/articles/algorithms_en.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"[en] Algorithms description","text":"Reinert M., “Une méthode de classification descendante hiérarchique : application à l’analyse lexicale par contexte”, Cahiers de l’analyse des données, Volume 8, Numéro 2, 1983. http://www.numdam.org/item/?id=CAD_1983__8_2_187_0 Reinert M., “Alceste une méthodologie d’analyse des données textuelles et une application: Aurelia De Gerard De Nerval”, Bulletin de Méthodologie Sociologique, Volume 26, Numéro 1, 1990. https://doi.org/10.1177/075910639002600103 Reinert M., “Une méthode de classification des énoncés d’un corpus présentée à l’aide d’une application”, Les cahiers de l’analyse des données, Tome 15, Numéro 1, 1990. http://www.numdam.org/item/?id=CAD_1990__15_1_21_0","code":""},{"path":"https://juba.github.io/rainette/articles/introduction_en.html","id":"corpus-preparation","dir":"Articles","previous_headings":"","what":"Corpus preparation","title":"[en] Introduction to rainette","text":"description Reinert clustering method implementation rainette, please see algorithms description vignette.","code":""},{"path":"https://juba.github.io/rainette/articles/introduction_en.html","id":"split-corpus-into-segments","dir":"Articles","previous_headings":"Corpus preparation","what":"Split corpus into segments","title":"[en] Introduction to rainette","text":"doesn’t take account terms frequencies presence / absence, assigns document one cluster, Reinert method must applied short “homogeneous” documents. ok work tweets short answers specific question, longer documents must first split short textual segments. can use split_segments() function , can applied directly tm quanteda corpus. article apply sample data_corpus_inaugural corpus provided quanteda. split_segments split original texts smaller chunks, attempting respect sentences punctuation possible. function takes two arguments : segment_size : preferred segment size, words segment_size_window : “window” looking best segment split, words. NULL, set 0.4 * segment_size. result function quanteda corpus, keeps original corpus metadata adds additional segment_source variable, keeps track segment belongs document.","code":"library(quanteda) library(rainette)  ## Split documents into segments corpus <- split_segments(data_corpus_inaugural, segment_size = 40) corpus ## Corpus consisting of 3,584 documents and 6 docvars. ## segment_source_1 : ## \"Fellow-Citizens of the Senate and of the House of Representa...\" ##  ## segment_source_2 : ## \"On the one hand, I was summoned by my Country, whose voice I...\" ##  ## segment_source_3 : ## \"as the asylum of my declining years - a retreat which was re...\" ##  ## segment_source_4 : ## \"On the other hand, the magnitude and difficulty of the trust...\" ##  ## segment_source_5 : ## \"could not but overwhelm with despondence one who (inheriting...\" ##  ## segment_source_6 : ## \"In this conflict of emotions all I dare aver is that it has ...\" ##  ## [ reached max_ndoc ... 3,578 more documents ] head(docvars(corpus)) ##   Year  President FirstName Party  segment_source \"segment_source\" ## 1 1789 Washington    George  none 1789-Washington   segment_source ## 2 1789 Washington    George  none 1789-Washington   segment_source ## 3 1789 Washington    George  none 1789-Washington   segment_source ## 4 1789 Washington    George  none 1789-Washington   segment_source ## 5 1789 Washington    George  none 1789-Washington   segment_source ## 6 1789 Washington    George  none 1789-Washington   segment_source"},{"path":"https://juba.github.io/rainette/articles/introduction_en.html","id":"dfm-computation","dir":"Articles","previous_headings":"Corpus preparation","what":"dfm computation","title":"[en] Introduction to rainette","text":"next step compute document-feature matrix. corpus object quanteda corpus, can tokenize use dfm() function. also filter terms appear less 10 segments using dfm_trim.","code":"tok <- tokens(corpus, remove_punct = TRUE) tok <- tokens_tolower(tok) tok <- tokens_remove(tok, stopwords(\"en\")) dtm <- dfm(tok) dtm <- dfm_trim(dtm, min_docfreq = 10)"},{"path":"https://juba.github.io/rainette/articles/introduction_en.html","id":"simple-clustering","dir":"Articles","previous_headings":"","what":"Simple clustering","title":"[en] Introduction to rainette","text":"now ready compute simple Reinert clustering using rainette() function. main arguments : k : number clusters compute. min_segment_size : minimum number terms segment. segment contains less number terms, merged following previous one come source document. default value 0, ie merging done. min_split_members : cluster smaller value, won’t split afterwards (default : 5). compute 5 clusters min_segment_size 15 : help exploring clustering results, rainette provides interactive interface can launched rainette_explor() : rainette_explor() interface interface allows change number clusters, displayed statistic, etc., see result real time. default specific terms displayed blue bar red one negative keyness (Show negative values checked). can also click Get R code button get R code reproduce current plot compute cluster membership. Cluster documents tab allows browse documents given cluster. can filter giving term regular expression Filter term field : rainette_explor() cluster documents tab can use cutree get document cluster level k : vector can used, example, new corpus metadata variable : , clusters assigned segments, original documents whole. clusters_by_doc_table allows display, original document, number segment belonging cluster : adding prop = TRUE, table displayed row percentages : Conversely, docs_by_cluster_table allows display, cluster, number proportion original document including least one segment cluster :","code":"res <- rainette(dtm, k = 5, min_segment_size = 15) rainette_explor(res, dtm, corpus) cluster <- cutree(res, k = 5) corpus$cluster <- cutree(res, k = 5) head(docvars(corpus)) ##   Year  President FirstName Party  segment_source \"segment_source\" cluster ## 1 1789 Washington    George  none 1789-Washington   segment_source       4 ## 2 1789 Washington    George  none 1789-Washington   segment_source       4 ## 3 1789 Washington    George  none 1789-Washington   segment_source       3 ## 4 1789 Washington    George  none 1789-Washington   segment_source       3 ## 5 1789 Washington    George  none 1789-Washington   segment_source       5 ## 6 1789 Washington    George  none 1789-Washington   segment_source       5 clusters_by_doc_table(corpus, clust_var = \"cluster\") ## # A tibble: 59 × 6 ##    doc_id          clust_1 clust_2 clust_3 clust_4 clust_5 ##    <chr>             <int>   <int>   <int>   <int>   <int> ##  1 1789-Washington       0       0       4      27       6 ##  2 1793-Washington       0       0       0       0       4 ##  3 1797-Adams            8       0       5      44       2 ##  4 1801-Jefferson       18       0       3      21       2 ##  5 1805-Jefferson        2       3       6      43       3 ##  6 1809-Madison          0       0       4      17       7 ##  7 1813-Madison          0       5       5      20       3 ##  8 1817-Monroe           2       0      27      47      12 ##  9 1821-Monroe           2       0      37      66      10 ## 10 1825-Adams            8       2      13      46       8 ## # … with 49 more rows clusters_by_doc_table(corpus, clust_var = \"cluster\", prop = TRUE) ## # A tibble: 59 × 6 ##    doc_id          clust_1 clust_2 clust_3 clust_4 clust_5 ##    <chr>             <dbl>   <dbl>   <dbl>   <dbl>   <dbl> ##  1 1789-Washington    0       0      10.8     73.0   16.2  ##  2 1793-Washington    0       0       0        0    100    ##  3 1797-Adams        13.6     0       8.47    74.6    3.39 ##  4 1801-Jefferson    40.9     0       6.82    47.7    4.55 ##  5 1805-Jefferson     3.51    5.26   10.5     75.4    5.26 ##  6 1809-Madison       0       0      14.3     60.7   25    ##  7 1813-Madison       0      15.2    15.2     60.6    9.09 ##  8 1817-Monroe        2.27    0      30.7     53.4   13.6  ##  9 1821-Monroe        1.74    0      32.2     57.4    8.70 ## 10 1825-Adams        10.4     2.60   16.9     59.7   10.4  ## # … with 49 more rows docs_by_cluster_table(corpus, clust_var = \"cluster\") ## # A tibble: 5 × 3 ##   cluster     n   `%` ##   <chr>   <int> <dbl> ## 1 clust_1    52  88.1 ## 2 clust_2    40  67.8 ## 3 clust_3    40  67.8 ## 4 clust_4    44  74.6 ## 5 clust_5    34  57.6"},{"path":"https://juba.github.io/rainette/articles/introduction_en.html","id":"double-clustering","dir":"Articles","previous_headings":"","what":"Double clustering","title":"[en] Introduction to rainette","text":"rainette also provides “double clustering” algorithm, described algorithms description vignette : two simple clusterings computed different min_segment_size values, crossed together get robust clusters. can done rainette2() function, can applied two already computed simple clusterings. , compute min_segment_size 10 15. use rainette2() combine . max_k argument used specify maximum number clusters. One important argument rainette2() full argument : full = TRUE (default), best crossed clusters partition selection made keeping non empty crossed clusters. allows exhaustive search identify partition either highest sum association χ², one highest total size. However, computation times can rise rapidly number clusters. full = FALSE, crossed clusters whose clusters mutually associated kept. Computations much faster, highest k level available partitions may lower, partitions highest association χ² values can identified. noted : full = TRUE, runtime high can add parallel = TRUE argument paralellise computations (won’t work Windows, though, may use much RAM). cases, resulting object tibble , level k, optimal partitions characteristics. Another interactive interface available explore results. launched rainette2_explor(). rainette2_explor() interface interface similar previous one, except dendrogram anymore, single barplot cluster sizes instead. careful number NA (assigned segments), can quite high. points assigned cluster, can use rainette2_complete_groups() assign nearest one using k-nearest-neighbors algorithm (k=1). However may recommended loose “robustness” new clusters computed rainette2().","code":"res1 <- rainette(dtm, k = 5, min_segment_size = 10) res2 <- rainette(dtm, k = 5, min_segment_size = 15) res <- rainette2(res1, res2, max_k = 5) rainette2_explor(res, dtm, corpus) clusters <- cutree(res, k = 5) clusters_completed <- rainette2_complete_groups(dtm, clusters)"},{"path":[]},{"path":"https://juba.github.io/rainette/articles/introduction_usage.html","id":"importation","dir":"Articles","previous_headings":"Préparation du corpus","what":"Importation","title":"[fr] Utilisation de rainette","text":"La première étape consiste à importer votre corpus dans R. Vous pouvez utiliser un corpus au format tm ou quanteda, ou bien utiliser la fonction import_corpus_iramuteq pour importer directement un corpus depuis un fichier texte au format Iramuteq. Dans ce cas vous obtiendrez un objet de type corpus du package quanteda. Les métadonnées éventuelles présentes dans le fichier (variables étoilées) sont importées en tant que métadonnées du corpus (variables de docvars(corpus)). Pour ce document, va importer le texte du Manifeste du parti communiste (Karl Marx et Friedrich Engels, 1848, source wikisource). Celui-ci est placé dans un fichier texte au format Iramuteq fourni avec rainette. Le corpus est composé de quatre documents, un document par partie de l’ouvrage. peut vérifier que notre corpus est bien constitué de quatre documents (l’introduction et les trois parties principales), et d’une variable de métadonnée : Cette variable de métadonnée est justement la partie correspondant au texte :","code":"library(rainette) library(quanteda)  ## Import du corpus fichier <- system.file(\"extdata\", \"manifeste_pc.txt\", package = \"rainette\") corpus <- import_corpus_iramuteq(fichier) corpus ## Corpus consisting of 4 documents and 1 docvar. ## text1 : ## \"Un spectre hante l’Europe, le spectre du communisme. Toutes ...\" ##  ## text2 : ## \"L’histoire de toute société jusqu’à nos jours n’a été que l’...\" ##  ## text3 : ## \"Quelle est la position des communistes vis-à-vis des proléta...\" ##  ## text4 : ## \"Par leur position historique, les aristocraties françaises e...\" docvars(corpus) ##   partie ## 1  intro ## 2      I ## 3     II ## 4    III"},{"path":"https://juba.github.io/rainette/articles/introduction_usage.html","id":"découpage-en-segments","dir":"Articles","previous_headings":"Préparation du corpus","what":"Découpage en segments","title":"[fr] Utilisation de rainette","text":"La méthode Reinert de classification s’applique à des segments de texte relativement courts, et non à des textes longs. Une première étape consiste donc à découper chaque texte du corpus en segments via la fonction split_segments(). Ici découpe en segments d’environ 40 mots (l’algorithme essaie de tenir compte de la ponctuation pour, par exemple, placer les césures entre des phrases ou au niveau d’une virgule). Notre corpus est désormais constitué de 278 segments et 2 variables de métadonnées : Si regarde les nouvelles métadonnées, peut voir que la variable partie été dupliquée pour chaque segment correspondant, et une nouvelle variable segment_source indique le document d’origine du segment. peut aussi visualiser les premiers segments de texte calculés :","code":"corpus <- split_segments(corpus, segment_size = 40) corpus ## Corpus consisting of 278 documents and 3 docvars. ## segment_source_1 : ## \"Un spectre hante l'Europe, le spectre du communisme. Toutes ...\" ##  ## segment_source_2 : ## \"Quelle est l'opposition qui, à son tour, n'a pas relancé à s...\" ##  ## segment_source_3 : ## \"à la face du monde entier, leur manière de voir, leurs buts ...\" ##  ## segment_source_4 : ## \"L'histoire de toute société jusqu'à nos jours n'a été que l'...\" ##  ## segment_source_5 : ## \"une guerre qui finissait toujours, ou par une transformation...\" ##  ## segment_source_6 : ## \"Dans la Rome antique, nous trouvons des patriciens, des chev...\" ##  ## [ reached max_ndoc ... 272 more documents ] head(docvars(corpus)) ##   partie segment_source \"segment_source\" ## 1  intro          text1   segment_source ## 2  intro          text1   segment_source ## 3  intro          text1   segment_source ## 4      I          text2   segment_source ## 5      I          text2   segment_source ## 6      I          text2   segment_source as.character(corpus)[1:2] ##                                                                                                                                                                                                                                                                                                                                          segment_source_1  ## \"Un spectre hante l'Europe, le spectre du communisme. Toutes les puissances de la vieille Europe se sont unies en une Sainte-Alliance pour traquer ce spectre : le Pape et le Czar, Metternich et Guizot, les radicaux de France et les policiers d'Allemagne.\\nQuelle est l'opposition que n'ont pas accusée de communisme ses adversaires au pouvoir ?\"  ##                                                                                                                                                                                                                                                                                                                                          segment_source_2  ##                       \"Quelle est l'opposition qui, à son tour, n'a pas relancé à ses adversaires de droite ou de gauche l'épithète flétrissante de communiste ?\\nDeux choses ressortent de ces faits :\\n1° Déjà le communisme est reconnu par toutes les puissances d'Europe comme une puissance ;\\n2° Il est grand temps que les communistes exposent,\""},{"path":"https://juba.github.io/rainette/articles/introduction_usage.html","id":"calcul-et-traitement-de-la-matrice-termes-documents","dir":"Articles","previous_headings":"Préparation du corpus","what":"Calcul et traitement de la matrice termes-documents","title":"[fr] Utilisation de rainette","text":"L’étape suivante est de calculer la matrice termes-documents (dtm), grand tableau numérique comportant les documents en lignes, les termes en colonnes, et comme valeurs le nombre d’occurrences de chaque terme dans chaque document. Notre corpus étant au format quanteda, va utiliser les fonctions de cette extension. commence par tokeniser le corpus en supprimant nombre et ponctuations, supprime les mots outils les plus courants et convertit tous les termes en minuscules, puis calule la matrice termes-documents avec la fonction dfm(). supprime ensuite de la matrice les termes apparaissant dans moins de 3 segments. De nombreux autres traitements seraient possibles, mais se contentera de cette matrice pour cet exemple.","code":"tok <- tokens(corpus, remove_punct = TRUE, remove_numbers = TRUE) tok <- tokens_remove(tok, stopwords(\"fr\")) tok <- tokens_tolower(tok) dtm <- dfm(tok) dtm <- dfm_trim(dtm, min_docfreq = 3)"},{"path":"https://juba.github.io/rainette/articles/introduction_usage.html","id":"classification-simple","dir":"Articles","previous_headings":"","what":"Classification simple","title":"[fr] Utilisation de rainette","text":"Une fois notre matrice calculée, peut procéder à une première forme de classification : une classification descendante hiérarchique simple, calculée avec la fonction rainette(). peut lui passer plusieurs arguments, notamment : k : le nombre maximal de classes souhaitées. min_split_members : le nombre minimal de documents pour qu’une classe soit scindée en deux à l’étape suivante de la classification. min_segment_size : le nombre minimal de termes par segment. En effet, lors de la tokenisation et du calcul de la dtm, certaines formes (mots-outils, mots trop peu fréquents) ont été supprimées, nos segments peuvent donc varier en taille (entendue comme le nombre de termes encore présents). Avec min_segment_size = 10, les segments comportant moins de 10 formes sont regroupés avec le segment suivant ou précédent du même document (si possible) jusqu’à atteindre la taille minimale souhaitée. L’objet résultat ne nous dit pas grand chose en lui-même : Pour faciliter l’exploration des résultats, rainette propose une interface interactive qui peut être lancée avec la fonction rainette_explor() : L’interface devrait ressembler à quelque chose comme ça : Interface de rainette_explor() Il est possible de modifier le nombre de classes, la statistique utilisée dans les graphiques (spécificité, termes les plus fréquents), etc. Par défaut, les graphiques sous chaque classe indiquent les termes les plus caractéristiques du groupe positivement (en bleu) ou négativement (en rouge et si vous avez coché la case Show negative values). Cette interface vous permet d’expérimenter librement sur le nombre de classes et leur interprétation. L’onglet Cluster documents permet à tout moment de visualiser les documents d’une classe. Vous pouvez également filtrer ces documents en saisissant un mot ou une expression régulière dans le champ Filter term : Onglet “Cluster documents” de rainette_explor() Dans l’onglet Summary, vous pouvez également cliquer sur Get R code pour obtenir le code R correspondant au graphique actuellement affiché, ainsi que la commande cutree qui vous permet de récupérer les groupes d’appartenance de chaque document du corpus, là aussi selon le nombre de groupes actuellement affichés. Vous pouvez par exemple utiliser l’appel de cutree pour ajouter comme nouvelle métadonnée du corpus le groupe d’appartenance de chaque segment pour la classification en 5 classes : Ici les classes ont attribuées aux segments, et non aux documents dans leur ensemble. La fonction clusters_by_doc_table() permet d’afficher, pour chaque document (ici chacune des quatre parties du texte), le nombre de segments de chaque groupe : En ajoutant prop = TRUE, cette répartition peut être visualisée en pourcentages : À l’inverse, docs_by_cluster_table() permet de visualiser, pour chaque groupe, le nombre et la proportion de documents d’origine comportant au moins un segment de ce groupe :","code":"res <- rainette(dtm, k = 5, min_segment_size = 10, min_split_members = 10) res ##  ## Call: ## rainette(dtm = dtm, k = 5, min_segment_size = 10, min_split_members = 10) ##  ## Cluster method   : reinert  ## Number of objects: 5 rainette_explor(res, dtm, corpus) ## Clustering description plot rainette_plot(res, dtm, k = 5, type = \"bar\", n_terms = 20, free_scales = FALSE,     measure = \"chi2\", show_negative = \"TRUE\", text_size = 11) ## Groups  cutree(res, k = 5) corpus$groupe <- cutree(res, k = 5) head(docvars(corpus)) ##   partie segment_source \"segment_source\" groupe ## 1  intro          text1   segment_source      3 ## 2  intro          text1   segment_source      3 ## 3  intro          text1   segment_source      3 ## 4      I          text2   segment_source      1 ## 5      I          text2   segment_source      1 ## 6      I          text2   segment_source      1 clusters_by_doc_table(corpus, clust_var = \"groupe\") ## # A tibble: 4 × 6 ##   doc_id clust_1 clust_2 clust_3 clust_4 clust_5 ##   <chr>    <int>   <int>   <int>   <int>   <int> ## 1 text1        0       0       3       0       0 ## 2 text2       14      28       5      36      20 ## 3 text3        8      10       6       7      44 ## 4 text4       23      32      29       5       8 clusters_by_doc_table(corpus, clust_var = \"groupe\", prop = TRUE) ## # A tibble: 4 × 6 ##   doc_id clust_1 clust_2 clust_3 clust_4 clust_5 ##   <chr>    <dbl>   <dbl>   <dbl>   <dbl>   <dbl> ## 1 text1      0       0    100       0       0    ## 2 text2     13.6    27.2    4.85   35.0    19.4  ## 3 text3     10.7    13.3    8       9.33   58.7  ## 4 text4     23.7    33.0   29.9     5.15    8.25 docs_by_cluster_table(corpus, clust_var = \"groupe\") ## # A tibble: 5 × 3 ##   cluster     n   `%` ##   <chr>   <int> <dbl> ## 1 clust_1     3    75 ## 2 clust_2     3    75 ## 3 clust_3     4   100 ## 4 clust_4     3    75 ## 5 clust_5     3    75"},{"path":"https://juba.github.io/rainette/articles/introduction_usage.html","id":"classification-double","dir":"Articles","previous_headings":"","what":"Classification double","title":"[fr] Utilisation de rainette","text":"Le deuxième type de classification proposé est une classification double : selon la méthode proposée par Max Reinert, effectue deux classifications simples en faisant varier la taille minimale des segments, puis “croise” les résultats de ces deux classifications pour déterminer de nouvelles classes, potentiellement plus robustes. Pour plus de détails sur la classifcation double, se référer à la vignette de description des algorithmes. Une classification double utilise la fonction rainette2(). commence par effectuer les deux classifications simples, ici une avec une taille de segment minimale à 10, et une autre à 15 : Puis utilise rainette2() sur ces deux objets résultats, en lui indiquant le nombre maximal de classes à calculer (argument max_k). Un paramètre important de rainette2() est le paramètre full : Si full = TRUE (valeur par défaut), la sélection des partitions optimales de classes croisées se fait en conservant toutes les classes croisées non nulles. Ceci permet une recherche “exhaustive” et permet de sélectionner les partitions ayant l’effectif total le plus élevé ou bien le χ² d’association le plus fort. Les temps de calcul peuvent cependant être longs si le nombre de classes de départ est important. Si full = FALSE, seules les classes croisées dont les deux memebres sont les plus associés mutuellement au sens du χ² sont conservées. Les calculs sont beaucoup plus rapides, mais le k maximal risque d’être moins élevé, et seules les partitions avec le χ² d’association le plus élevé sont conservées. À noter que pour full = TRUE, si le temps d’exécution est trop long il est possible d’utiliser également parallel = TRUE qui permet de paralléliser une partie des calculs (attention cette option ne fonctionne pas sous Windows, et elle utilise davantage de RAM). Dans tous les cas l’objet résultat contient, pour chaque valeur de k, les partitions optimales trouvées et leurs caractéristiques. Là encore, une interface interactive est proposée pour visualiser et explorer ces résultats. Elle se lance via la fonction rainette2_explor() : Interface de rainette2_explor() L’interface est très semblable à la précédente, sauf qu’il n’y plus de dendrogramme mais à la place un diagramme en barre des effectifs des groupes. Soyez attentifs aux NA, qui représentent les segments non classés : contrairement à la classification simple, ils peuvent ici être assez nombreux. Si certains segments n’ont pas été affecté à un groupe, vous pouvez utiliser rainette2_complete_groups() pour les assigner au groupe le plus proche selon une méthode k-nearest neighbors (avec k=1). Ceci n’est cependant pas forcément conseillé car les classes perdont du coup une partie de la “robustesse” acquise par la classification double.","code":"res1 <- rainette(dtm, k = 7, min_segment_size = 10) res2 <- rainette(dtm, k = 7, min_segment_size = 15) res <- rainette2(res1, res2, max_k = 7) rainette2_explor(res, dtm, corpus) groupes <- cutree(res, k = 5) groupes_complets <- rainette2_complete_groups(dtm, groupes)"},{"path":"https://juba.github.io/rainette/articles/introduction_usage.html","id":"traitements-complémentaires","dir":"Articles","previous_headings":"","what":"Traitements complémentaires","title":"[fr] Utilisation de rainette","text":"Dans sa version originale, la méthode Reinert de classification est souvent suivie par une analyse complémentaire centrée sur les mots-outils et par différentes représentations graphiques, notamment en projetant les classes obtenues sur des résultats d’analyses factorielles. trouvera une explication et un exemple d’application, ainsi qu’un aperçu des fondements théoriques de la méthode dans l’article de Claire Tissot : Analyse textuelle du roman « Sarrasine » d’Honoré de Balzac : de la recherche de thèmes à la sémiotique.","code":""},{"path":"https://juba.github.io/rainette/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Julien Barnier. Author, maintainer. Florian Privé. Contributor.","code":""},{"path":"https://juba.github.io/rainette/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Barnier J (2023). rainette: Reinert Method Textual Data Clustering. R package version 0.3.0.9000, https://juba.github.io/rainette/.","code":"@Manual{,   title = {rainette: The Reinert Method for Textual Data Clustering},   author = {Julien Barnier},   year = {2023},   note = {R package version 0.3.0.9000},   url = {https://juba.github.io/rainette/}, }"},{"path":"https://juba.github.io/rainette/index.html","id":"rainette","dir":"","previous_headings":"","what":"The Reinert Method for Textual Data Clustering","title":"The Reinert Method for Textual Data Clustering","text":"Rainette R package implements variant Reinert textual clustering method. method available softwares Iramuteq (free software) Alceste (commercial, closed source).","code":""},{"path":"https://juba.github.io/rainette/index.html","id":"features","dir":"","previous_headings":"","what":"Features","title":"The Reinert Method for Textual Data Clustering","text":"Simple double clustering algorithms Plot functions shiny interfaces visualise explore clustering results Utility functions split corpus segments import corpus Iramuteq format","code":""},{"path":"https://juba.github.io/rainette/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"The Reinert Method for Textual Data Clustering","text":"package installable CRAN. development version installable R-universe.","code":"install_packages(\"rainette\") install.packages(\"rainette\", repos = \"https://juba.r-universe.dev\")"},{"path":"https://juba.github.io/rainette/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"The Reinert Method for Textual Data Clustering","text":"Let’s start example corpus provided excellent quanteda package. First, ’ll use split_segments() split document segments 40 words (punctuation taken account). Next, ’ll apply preprocessing compute document-term matrix quanteda functions. can apply simple clustering matrix rainette() function. specify number clusters (k), minimum number forms segment (min_segment_size). Segments include enough forms merged following previous one possible. can use rainette_explor() shiny interface visualise explore different clusterings k. rainette_explor() interface Cluster documents tab allows browse filter documents cluster. rainette_explor() documents tab can also directly generate clusters description plot given k rainette_plot(). cut tree chosen k add group membership variable corpus metadata. addition , can also perform double clustering, ie two simple clusterings produced different min_segment_size “crossed” generate robust clusters. , use rainette2() two rainette() results : can use rainette2_explor() explore visualise results. rainette2_explor() interface","code":"library(quanteda) data_corpus_inaugural corpus <- split_segments(data_corpus_inaugural, segment_size = 40) tok <- tokens(corpus, remove_punct = TRUE) tok <- tokens_remove(tok, stopwords(\"en\")) dtm <- dfm(tok, tolower = TRUE) dtm <- dfm_trim(dtm, min_docfreq = 10) res <- rainette(dtm, k = 6, min_segment_size = 15) rainette_explor(res, dtm, corpus) rainette_plot(res, dtm, k = 5) docvars(corpus)$cluster <- cutree(res, k = 5) res1 <- rainette(dtm, k = 5, min_segment_size = 10) res2 <- rainette(dtm, k = 5, min_segment_size = 15) res <- rainette2(res1, res2, max_k = 5) rainette2_explor(res, dtm, corpus)"},{"path":"https://juba.github.io/rainette/index.html","id":"tell-me-more","dir":"","previous_headings":"","what":"Tell me more","title":"The Reinert Method for Textual Data Clustering","text":"Two vignettes available : Introduction usage vignette : english, french Algorithms description vignette : english, french","code":""},{"path":"https://juba.github.io/rainette/index.html","id":"credits","dir":"","previous_headings":"","what":"Credits","title":"The Reinert Method for Textual Data Clustering","text":"clustering method created Max Reinert, described several articles, notably : Reinert M., “Une méthode de classification descendante hiérarchique : application à l’analyse lexicale par contexte”, Cahiers de l’analyse des données, Volume 8, Numéro 2, 1983. http://www.numdam.org/item/?id=CAD_1983__8_2_187_0 Reinert M., “Alceste une méthodologie d’analyse des données textuelles et une application: Aurelia De Gerard De Nerval”, Bulletin de Méthodologie Sociologique, Volume 26, Numéro 1, 1990. https://doi.org/10.1177/075910639002600103 Reinert M., “Une méthode de classification des énoncés d’un corpus présentée à l’aide d’une application”, Les cahiers de l’analyse des données, Tome 15, Numéro 1, 1990. http://www.numdam.org/item/?id=CAD_1990__15_1_21_0 Thanks Pierre Ratineau, author Iramuteq, providing free software open source. Even R code almost entirely rewritten, precious resource understand algorithms. Many thanks Sébastien Rochette creation hex logo. Many thanks Florian Privé work rewriting optimizing Rcpp code.","code":""},{"path":"https://juba.github.io/rainette/reference/cluster_tab.html","id":null,"dir":"Reference","previous_headings":"","what":"Split a dtm into two clusters with reinert algorithm — cluster_tab","title":"Split a dtm into two clusters with reinert algorithm — cluster_tab","text":"Split dtm two clusters reinert algorithm","code":""},{"path":"https://juba.github.io/rainette/reference/cluster_tab.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split a dtm into two clusters with reinert algorithm — cluster_tab","text":"","code":"cluster_tab(dtm, cc_test = 0.3, tsj = 3)"},{"path":"https://juba.github.io/rainette/reference/cluster_tab.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split a dtm into two clusters with reinert algorithm — cluster_tab","text":"dtm split, passed rainette cc_test maximum contingency coefficient value feature kept groups. tsj minimum feature frequency dtm","code":""},{"path":"https://juba.github.io/rainette/reference/cluster_tab.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split a dtm into two clusters with reinert algorithm — cluster_tab","text":"object class hclust rainette","code":""},{"path":"https://juba.github.io/rainette/reference/cluster_tab.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Split a dtm into two clusters with reinert algorithm — cluster_tab","text":"Internal function, used directly","code":""},{"path":"https://juba.github.io/rainette/reference/clusters_by_doc_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns the number of segment of each cluster for each source document — clusters_by_doc_table","title":"Returns the number of segment of each cluster for each source document — clusters_by_doc_table","text":"Returns number segment cluster source document","code":""},{"path":"https://juba.github.io/rainette/reference/clusters_by_doc_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns the number of segment of each cluster for each source document — clusters_by_doc_table","text":"","code":"clusters_by_doc_table(obj, clust_var = NULL, doc_id = NULL, prop = FALSE)"},{"path":"https://juba.github.io/rainette/reference/clusters_by_doc_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns the number of segment of each cluster for each source document — clusters_by_doc_table","text":"obj corpus, tokens dtm object clust_var name docvar clusters doc_id docvar identifying source document prop TRUE, returns percentage cluster document","code":""},{"path":"https://juba.github.io/rainette/reference/clusters_by_doc_table.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Returns the number of segment of each cluster for each source document — clusters_by_doc_table","text":"function useful previously segmented corpus. doc_id NULL sement_source docvar, used instead.","code":""},{"path":[]},{"path":"https://juba.github.io/rainette/reference/clusters_by_doc_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Returns the number of segment of each cluster for each source document — clusters_by_doc_table","text":"","code":"# \\donttest{ require(quanteda) #> Loading required package: quanteda #> Warning: Your current locale is not in the list of available locales. Some functions may not work properly. Refer to stri_locale_list() for more details on known locale specifiers. #> Warning: Your current locale is not in the list of available locales. Some functions may not work properly. Refer to stri_locale_list() for more details on known locale specifiers. #> Package version: 3.2.4 #> Unicode version: 14.0 #> ICU version: 70.1 #> Parallel computing: 2 of 2 threads used. #> See https://quanteda.io for tutorials and examples. corpus <- data_corpus_inaugural corpus <- head(corpus, n = 10) corpus <- split_segments(corpus) #>   Splitting... #>   Done. tok <- tokens(corpus, remove_punct = TRUE) tok <- tokens_remove(tok, stopwords(\"en\")) dtm <- dfm(tok, tolower = TRUE) dtm <- dfm_trim(dtm, min_docfreq = 2) res <- rainette(dtm, k = 3, min_segment_size = 15) #>   Merging segments to comply with min_segment_size... #>   Clustering... #>   Done. corpus$cluster <- cutree(res, k = 3) clusters_by_doc_table(corpus, clust_var = \"cluster\", prop = TRUE) #> # A tibble: 10 × 4 #>    doc_id          clust_1 clust_2 clust_3 #>    <chr>             <dbl>   <dbl>   <dbl> #>  1 1789-Washington   29.7     56.8    13.5 #>  2 1793-Washington  100        0       0   #>  3 1797-Adams        13.6     64.4    22.0 #>  4 1801-Jefferson     9.09    72.7    18.2 #>  5 1805-Jefferson    10.5     52.6    36.8 #>  6 1809-Madison      25       32.1    42.9 #>  7 1813-Madison      21.2     33.3    45.5 #>  8 1817-Monroe       18.2     22.7    59.1 #>  9 1821-Monroe       14.8     13.9    71.3 #> 10 1825-Adams        19.5     31.2    49.4 # }"},{"path":"https://juba.github.io/rainette/reference/cutree.html","id":null,"dir":"Reference","previous_headings":"","what":"Cut a tree into groups — cutree","title":"Cut a tree into groups — cutree","text":"Cut tree groups","code":""},{"path":"https://juba.github.io/rainette/reference/cutree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cut a tree into groups — cutree","text":"","code":"cutree(tree, ...)"},{"path":"https://juba.github.io/rainette/reference/cutree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cut a tree into groups — cutree","text":"tree hclust tree object cut ... arguments passed methods","code":""},{"path":"https://juba.github.io/rainette/reference/cutree.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cut a tree into groups — cutree","text":"vector group membership.","code":""},{"path":"https://juba.github.io/rainette/reference/cutree.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cut a tree into groups — cutree","text":"tree class rainette, invokes cutree_rainette(). Otherwise, just run stats::cutree().","code":""},{"path":"https://juba.github.io/rainette/reference/cutree_rainette.html","id":null,"dir":"Reference","previous_headings":"","what":"Cut a rainette result tree into groups of documents — cutree_rainette","title":"Cut a rainette result tree into groups of documents — cutree_rainette","text":"Cut rainette result tree groups documents","code":""},{"path":"https://juba.github.io/rainette/reference/cutree_rainette.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cut a rainette result tree into groups of documents — cutree_rainette","text":"","code":"cutree_rainette(hres, k = NULL, h = NULL, ...)"},{"path":"https://juba.github.io/rainette/reference/cutree_rainette.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cut a rainette result tree into groups of documents — cutree_rainette","text":"hres rainette result object cut k desired number clusters h unsupported ... arguments passed methods","code":""},{"path":"https://juba.github.io/rainette/reference/cutree_rainette.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cut a rainette result tree into groups of documents — cutree_rainette","text":"vector group membership.","code":""},{"path":"https://juba.github.io/rainette/reference/cutree_rainette2.html","id":null,"dir":"Reference","previous_headings":"","what":"Cut a rainette2 result object into groups of documents — cutree_rainette2","title":"Cut a rainette2 result object into groups of documents — cutree_rainette2","text":"Cut rainette2 result object groups documents","code":""},{"path":"https://juba.github.io/rainette/reference/cutree_rainette2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cut a rainette2 result object into groups of documents — cutree_rainette2","text":"","code":"cutree_rainette2(res, k, criterion = c(\"chi2\", \"n\"), ...)"},{"path":"https://juba.github.io/rainette/reference/cutree_rainette2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cut a rainette2 result object into groups of documents — cutree_rainette2","text":"res rainette2 result object cut k desired number clusters criterion criterion use choose best partition. chi2 means partition maximum sum chi2, n partition maximum size. ... arguments passed methods","code":""},{"path":"https://juba.github.io/rainette/reference/cutree_rainette2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cut a rainette2 result object into groups of documents — cutree_rainette2","text":"vector group membership.","code":""},{"path":[]},{"path":"https://juba.github.io/rainette/reference/docs_by_cluster_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns, for each cluster, the number of source documents with at least n\nsegments of this cluster — docs_by_cluster_table","title":"Returns, for each cluster, the number of source documents with at least n\nsegments of this cluster — docs_by_cluster_table","text":"Returns, cluster, number source documents least n segments cluster","code":""},{"path":"https://juba.github.io/rainette/reference/docs_by_cluster_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns, for each cluster, the number of source documents with at least n\nsegments of this cluster — docs_by_cluster_table","text":"","code":"docs_by_cluster_table(obj, clust_var = NULL, doc_id = NULL, threshold = 1)"},{"path":"https://juba.github.io/rainette/reference/docs_by_cluster_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns, for each cluster, the number of source documents with at least n\nsegments of this cluster — docs_by_cluster_table","text":"obj corpus, tokens dtm object clust_var name docvar clusters doc_id docvar identifying source document threshold minimal number segments given cluster document must include counted","code":""},{"path":"https://juba.github.io/rainette/reference/docs_by_cluster_table.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Returns, for each cluster, the number of source documents with at least n\nsegments of this cluster — docs_by_cluster_table","text":"function useful previously segmented corpus. doc_id NULL sement_source docvar, used instead.","code":""},{"path":[]},{"path":"https://juba.github.io/rainette/reference/docs_by_cluster_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Returns, for each cluster, the number of source documents with at least n\nsegments of this cluster — docs_by_cluster_table","text":"","code":"# \\donttest{ require(quanteda) corpus <- data_corpus_inaugural corpus <- head(corpus, n = 10) corpus <- split_segments(corpus) #>   Splitting... #>   Done. tok <- tokens(corpus, remove_punct = TRUE) tok <- tokens_remove(tok, stopwords(\"en\")) dtm <- dfm(tok, tolower = TRUE) dtm <- dfm_trim(dtm, min_docfreq = 2) res <- rainette(dtm, k = 3, min_segment_size = 15) #>   Merging segments to comply with min_segment_size... #>   Clustering... #>   Done. corpus$cluster <- cutree(res, k = 3) docs_by_cluster_table(corpus, clust_var = \"cluster\") #> # A tibble: 3 × 3 #>   cluster     n   `%` #>   <chr>   <int> <dbl> #> 1 clust_1    10   100 #> 2 clust_2     9    90 #> 3 clust_3     9    90 # }"},{"path":"https://juba.github.io/rainette/reference/import_corpus_iramuteq.html","id":null,"dir":"Reference","previous_headings":"","what":"Import a corpus in Iramuteq format — import_corpus_iramuteq","title":"Import a corpus in Iramuteq format — import_corpus_iramuteq","text":"Import corpus Iramuteq format","code":""},{"path":"https://juba.github.io/rainette/reference/import_corpus_iramuteq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import a corpus in Iramuteq format — import_corpus_iramuteq","text":"","code":"import_corpus_iramuteq(f, id_var = NULL, thematics = c(\"remove\", \"split\"), ...)"},{"path":"https://juba.github.io/rainette/reference/import_corpus_iramuteq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import a corpus in Iramuteq format — import_corpus_iramuteq","text":"f file name connection id_var name metadata variable used documents id thematics \"remove\", thematics lines removed. \"split\", texts splitted thematic, metadata duplicated accordingly ... arguments passed file f file name.","code":""},{"path":"https://juba.github.io/rainette/reference/import_corpus_iramuteq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import a corpus in Iramuteq format — import_corpus_iramuteq","text":"quanteda corpus object. Note metadata variables docvars imported characters.","code":""},{"path":"https://juba.github.io/rainette/reference/import_corpus_iramuteq.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Import a corpus in Iramuteq format — import_corpus_iramuteq","text":"description Iramuteq corpus format can found : http://www.iramuteq.org/documentation/html/2-2-2-les-regles-de-formatages","code":""},{"path":"https://juba.github.io/rainette/reference/merge_segments.html","id":null,"dir":"Reference","previous_headings":"","what":"Merges segments according to minimum segment size — merge_segments","title":"Merges segments according to minimum segment size — merge_segments","text":"rainette_uc_index docvar","code":""},{"path":"https://juba.github.io/rainette/reference/merge_segments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merges segments according to minimum segment size — merge_segments","text":"","code":"merge_segments(dtm, min_segment_size = 10, doc_id = NULL)"},{"path":"https://juba.github.io/rainette/reference/merge_segments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merges segments according to minimum segment size — merge_segments","text":"dtm dtm segments min_segment_size minimum number forms segment doc_id character name dtm docvar identifies source documents.","code":""},{"path":"https://juba.github.io/rainette/reference/merge_segments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Merges segments according to minimum segment size — merge_segments","text":"original dtm new rainette_uc_id docvar.","code":""},{"path":"https://juba.github.io/rainette/reference/merge_segments.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Merges segments according to minimum segment size — merge_segments","text":"min_segment_size == 0, segments merged together. min_segment_size > 0 doc_id must provided unless corpus comes split_segments, case segment_source used default.","code":""},{"path":"https://juba.github.io/rainette/reference/order_docs.html","id":null,"dir":"Reference","previous_headings":"","what":"return documents indices ordered by CA first axis coordinates — order_docs","title":"return documents indices ordered by CA first axis coordinates — order_docs","text":"return documents indices ordered CA first axis coordinates","code":""},{"path":"https://juba.github.io/rainette/reference/order_docs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"return documents indices ordered by CA first axis coordinates — order_docs","text":"","code":"order_docs(m)"},{"path":"https://juba.github.io/rainette/reference/order_docs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"return documents indices ordered by CA first axis coordinates — order_docs","text":"m dtm compute CA order documents, converted integer matrix.","code":""},{"path":"https://juba.github.io/rainette/reference/order_docs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"return documents indices ordered by CA first axis coordinates — order_docs","text":"ordered list document indices","code":""},{"path":"https://juba.github.io/rainette/reference/order_docs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"return documents indices ordered by CA first axis coordinates — order_docs","text":"Internal function, used directly","code":""},{"path":"https://juba.github.io/rainette/reference/rainette.html","id":null,"dir":"Reference","previous_headings":"","what":"Corpus clustering based on the Reinert method - Simple clustering — rainette","title":"Corpus clustering based on the Reinert method - Simple clustering — rainette","text":"Corpus clustering based Reinert method - Simple clustering","code":""},{"path":"https://juba.github.io/rainette/reference/rainette.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Corpus clustering based on the Reinert method - Simple clustering — rainette","text":"","code":"rainette(   dtm,   k = 10,   min_segment_size = 0,   doc_id = NULL,   min_split_members = 5,   cc_test = 0.3,   tsj = 3,   min_members,   min_uc_size )"},{"path":"https://juba.github.io/rainette/reference/rainette.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Corpus clustering based on the Reinert method - Simple clustering — rainette","text":"dtm quanteda dfm object documents cluster, usually result split_segments() k maximum number clusters compute min_segment_size minimum number forms document doc_id character name dtm docvar identifies source documents. min_split_members try split groups fewer members cc_test contingency coefficient value feature selection tsj minimum frequency value feature selection min_members deprecated, use min_split_members instead min_uc_size deprecated, use min_segment_size instead","code":""},{"path":"https://juba.github.io/rainette/reference/rainette.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Corpus clustering based on the Reinert method - Simple clustering — rainette","text":"result list class hclust rainette. Besides elements hclust object, two results available : uce_groups give group document k group give group document maximum value k available","code":""},{"path":"https://juba.github.io/rainette/reference/rainette.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Corpus clustering based on the Reinert method - Simple clustering — rainette","text":"See references original articles method. Computations results may differ quite bit, see package vignettes details. dtm object automatically converted boolean. min_segment_size > 0 doc_id must provided unless corpus comes split_segments, case segment_source used default.","code":""},{"path":"https://juba.github.io/rainette/reference/rainette.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Corpus clustering based on the Reinert method - Simple clustering — rainette","text":"Reinert M, Une méthode de classification descendante hiérarchique : application à l'analyse lexicale par contexte, Cahiers de l'analyse des données, Volume 8, Numéro 2, 1983. http://www.numdam.org/item/?id=CAD_1983__8_2_187_0 Reinert M., Alceste une méthodologie d'analyse des données textuelles et une application: Aurelia De Gerard De Nerval, Bulletin de Méthodologie Sociologique, Volume 26, Numéro 1, 1990. doi:10.1177/075910639002600103","code":""},{"path":[]},{"path":"https://juba.github.io/rainette/reference/rainette.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Corpus clustering based on the Reinert method - Simple clustering — rainette","text":"","code":"# \\donttest{ require(quanteda) corpus <- data_corpus_inaugural corpus <- head(corpus, n = 10) corpus <- split_segments(corpus) #>   Splitting... #>   Done. tok <- tokens(corpus, remove_punct = TRUE) tok <- tokens_remove(tok, stopwords(\"en\")) dtm <- dfm(tok, tolower = TRUE) dtm <- dfm_trim(dtm, min_docfreq = 3) res <- rainette(dtm, k = 3, min_segment_size = 15) #>   Merging segments to comply with min_segment_size... #>   Clustering... #>   Done. # }"},{"path":"https://juba.github.io/rainette/reference/rainette2.html","id":null,"dir":"Reference","previous_headings":"","what":"Corpus clustering based on the Reinert method - Double clustering — rainette2","title":"Corpus clustering based on the Reinert method - Double clustering — rainette2","text":"Corpus clustering based Reinert method - Double clustering","code":""},{"path":"https://juba.github.io/rainette/reference/rainette2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Corpus clustering based on the Reinert method - Double clustering — rainette2","text":"","code":"rainette2(   x,   y = NULL,   max_k = 5,   min_segment_size1 = 10,   min_segment_size2 = 15,   doc_id = NULL,   min_members = 10,   min_chi2 = 3.84,   parallel = FALSE,   full = TRUE,   uc_size1,   uc_size2,   ... )"},{"path":"https://juba.github.io/rainette/reference/rainette2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Corpus clustering based on the Reinert method - Double clustering — rainette2","text":"x either quanteda dfm object result rainette() y x rainette() result, must another rainette() result dfm different uc size. max_k maximum number clusters compute min_segment_size1 x dfm, minimum uc size first clustering min_segment_size2 x dfm, minimum uc size second clustering doc_id character name dtm docvar identifies source documents. min_members minimum members cluster min_chi2 minimum chi2 cluster parallel TRUE, use parallel::mclapply compute partitions (work Windows, uses RAM) full TRUE, crossed groups kept compute optimal partitions, otherwise mutually associated groups kept. uc_size1 deprecated, use min_segment_size1 instead uc_size2 deprecated, use min_segment_size2 instead ... x dfm object, parameters passed rainette() simple clusterings","code":""},{"path":"https://juba.github.io/rainette/reference/rainette2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Corpus clustering based on the Reinert method - Double clustering — rainette2","text":"tibble optimal partitions found available value k rows, following columns : clusters list crossed original clusters used partition k number clusters chi2 sum chi2 value cluster n sum size cluster groups group membership document partition (NA assigned)","code":""},{"path":"https://juba.github.io/rainette/reference/rainette2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Corpus clustering based on the Reinert method - Double clustering — rainette2","text":"can pass quanteda dfm x object, function performs two simple clustering varying minimum uc size, proceed find optimal partitions based results clusterings. clusterings already computed, can pass x y arguments function look optimal partitions. doc_id must provided unless corpus comes split_segments, case segment_source used default. full = FALSE, computation may much faster, chi2 criterion one available best partition detection, result may optimal. details optimal partitions search algorithm, please see package vignettes.","code":""},{"path":"https://juba.github.io/rainette/reference/rainette2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Corpus clustering based on the Reinert method - Double clustering — rainette2","text":"Reinert M, Une méthode de classification descendante hiérarchique : application à l'analyse lexicale par contexte, Cahiers de l'analyse des données, Volume 8, Numéro 2, 1983. http://www.numdam.org/item/?id=CAD_1983__8_2_187_0 Reinert M., Alceste une méthodologie d'analyse des données textuelles et une application: Aurelia De Gerard De Nerval, Bulletin de Méthodologie Sociologique, Volume 26, Numéro 1, 1990.  doi:10.1177/075910639002600103","code":""},{"path":[]},{"path":"https://juba.github.io/rainette/reference/rainette2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Corpus clustering based on the Reinert method - Double clustering — rainette2","text":"","code":"# \\donttest{ require(quanteda) corpus <- data_corpus_inaugural corpus <- head(corpus, n = 10) corpus <- split_segments(corpus) #>   Splitting... #>   Done. tok <- tokens(corpus, remove_punct = TRUE) tok <- tokens_remove(tok, stopwords(\"en\")) dtm <- dfm(tok, tolower = TRUE) dtm <- dfm_trim(dtm, min_docfreq = 3)  res1 <- rainette(dtm, k = 5, min_segment_size = 10) #>   Merging segments to comply with min_segment_size... #>   Clustering... #>   Done. res2 <- rainette(dtm, k = 5, min_segment_size = 15) #>   Merging segments to comply with min_segment_size... #>   Clustering... #>   Done.  res <- rainette2(res1, res2, max_k = 4) #>   Searching for best partitions... #>   Computing size 2 partitions... #>   Computing size 3 partitions... #>   Computing size 4 partitions... #>   Selecting best partitions... #>   Done. # }"},{"path":"https://juba.github.io/rainette/reference/rainette2_complete_groups.html","id":null,"dir":"Reference","previous_headings":"","what":"Complete groups membership with knn classification — rainette2_complete_groups","title":"Complete groups membership with knn classification — rainette2_complete_groups","text":"Starting groups membership computed rainette2 clustering, every document assigned cluster reassigned using k-nearest neighbour classification.","code":""},{"path":"https://juba.github.io/rainette/reference/rainette2_complete_groups.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Complete groups membership with knn classification — rainette2_complete_groups","text":"","code":"rainette2_complete_groups(dfm, groups, k = 1, ...)"},{"path":"https://juba.github.io/rainette/reference/rainette2_complete_groups.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Complete groups membership with knn classification — rainette2_complete_groups","text":"dfm dfm object used rainette2 clustering. groups group membership computed cutree rainette2 result. k number neighbours considered. ... arguments passed FNN::knn.","code":""},{"path":"https://juba.github.io/rainette/reference/rainette2_complete_groups.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Complete groups membership with knn classification — rainette2_complete_groups","text":"Completed group membership vector.","code":""},{"path":[]},{"path":"https://juba.github.io/rainette/reference/rainette2_explor.html","id":null,"dir":"Reference","previous_headings":"","what":"Shiny gadget for rainette2 clustering exploration — rainette2_explor","title":"Shiny gadget for rainette2 clustering exploration — rainette2_explor","text":"Shiny gadget rainette2 clustering exploration","code":""},{"path":"https://juba.github.io/rainette/reference/rainette2_explor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shiny gadget for rainette2 clustering exploration — rainette2_explor","text":"","code":"rainette2_explor(res, dtm = NULL, corpus_src = NULL)"},{"path":"https://juba.github.io/rainette/reference/rainette2_explor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shiny gadget for rainette2 clustering exploration — rainette2_explor","text":"res result object rainette2 clustering dtm dfm object used compute clustering corpus_src quanteda corpus object used compute dtm","code":""},{"path":"https://juba.github.io/rainette/reference/rainette2_explor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Shiny gadget for rainette2 clustering exploration — rainette2_explor","text":"return value, called side effects.","code":""},{"path":[]},{"path":"https://juba.github.io/rainette/reference/rainette2_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a clustering description plot from a rainette2 result — rainette2_plot","title":"Generate a clustering description plot from a rainette2 result — rainette2_plot","text":"Generate clustering description plot rainette2 result","code":""},{"path":"https://juba.github.io/rainette/reference/rainette2_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a clustering description plot from a rainette2 result — rainette2_plot","text":"","code":"rainette2_plot(   res,   dtm,   k = NULL,   criterion = c(\"chi2\", \"n\"),   complete_groups = FALSE,   type = c(\"bar\", \"cloud\"),   n_terms = 15,   free_scales = FALSE,   measure = c(\"chi2\", \"lr\", \"frequency\", \"docprop\"),   show_negative = FALSE,   text_size = 10 )"},{"path":"https://juba.github.io/rainette/reference/rainette2_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a clustering description plot from a rainette2 result — rainette2_plot","text":"res result object rainette2 clustering dtm dfm object used compute clustering k number groups. NULL, use biggest number possible criterion criterion use choose best partition. chi2 means partition maximum sum chi2, n partition maximum size. complete_groups TRUE, documents NA cluster reaffected k-means clustering initialised current groups centers. type type term plots : barplot wordcloud n_terms number terms display keyness plots free_scales TRUE, keyness plots scale measure statistics compute show_negative TRUE, show negative keyness features text_size font size barplots, max word size wordclouds","code":""},{"path":"https://juba.github.io/rainette/reference/rainette2_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a clustering description plot from a rainette2 result — rainette2_plot","text":"gtable object.","code":""},{"path":[]},{"path":"https://juba.github.io/rainette/reference/rainette_explor.html","id":null,"dir":"Reference","previous_headings":"","what":"Shiny gadget for rainette clustering exploration — rainette_explor","title":"Shiny gadget for rainette clustering exploration — rainette_explor","text":"Shiny gadget rainette clustering exploration","code":""},{"path":"https://juba.github.io/rainette/reference/rainette_explor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shiny gadget for rainette clustering exploration — rainette_explor","text":"","code":"rainette_explor(res, dtm = NULL, corpus_src = NULL)"},{"path":"https://juba.github.io/rainette/reference/rainette_explor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shiny gadget for rainette clustering exploration — rainette_explor","text":"res result object rainette clustering dtm dfm object used compute clustering corpus_src quanteda corpus object used compute dtm","code":""},{"path":"https://juba.github.io/rainette/reference/rainette_explor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Shiny gadget for rainette clustering exploration — rainette_explor","text":"return value, called side effects.","code":""},{"path":[]},{"path":"https://juba.github.io/rainette/reference/rainette_explor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Shiny gadget for rainette clustering exploration — rainette_explor","text":"","code":"if (FALSE) { require(quanteda) corpus <- data_corpus_inaugural corpus <- head(corpus, n = 10) corpus <- split_segments(corpus) tok <- tokens(corpus, remove_punct = TRUE) tok <- tokens_remove(tok, stopwords(\"en\")) dtm <- dfm(tok, tolower = TRUE) dtm <- dfm_trim(dtm, min_docfreq = 3) res <- rainette(dtm, k = 3, min_segment_size = 15) rainette_explor(res, dtm, corpus) }"},{"path":"https://juba.github.io/rainette/reference/rainette_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a clustering description plot from a rainette result — rainette_plot","title":"Generate a clustering description plot from a rainette result — rainette_plot","text":"Generate clustering description plot rainette result","code":""},{"path":"https://juba.github.io/rainette/reference/rainette_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a clustering description plot from a rainette result — rainette_plot","text":"","code":"rainette_plot(   res,   dtm,   k = NULL,   type = c(\"bar\", \"cloud\"),   n_terms = 15,   free_scales = FALSE,   measure = c(\"chi2\", \"lr\", \"frequency\", \"docprop\"),   show_negative = FALSE,   text_size = NULL,   show_na_title = TRUE,   cluster_label = NULL,   keyness_plot_xlab = NULL )"},{"path":"https://juba.github.io/rainette/reference/rainette_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a clustering description plot from a rainette result — rainette_plot","text":"res result object rainette clustering dtm dfm object used compute clustering k number groups. NULL, use biggest number possible type type term plots : barplot wordcloud n_terms number terms display keyness plots free_scales TRUE, keyness plots scale measure statistics compute show_negative TRUE, show negative keyness features text_size font size barplots, max word size wordclouds show_na_title TRUE, show number NA plot title cluster_label define specific term clusters identification keyness plots. Default \"Cluster\" \"Cl.\" depending number groups. keyness_plot_xlab define specific x label keyness plots.","code":""},{"path":"https://juba.github.io/rainette/reference/rainette_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a clustering description plot from a rainette result — rainette_plot","text":"gtable object.","code":""},{"path":[]},{"path":"https://juba.github.io/rainette/reference/rainette_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a clustering description plot from a rainette result — rainette_plot","text":"","code":"# \\donttest{ require(quanteda) corpus <- data_corpus_inaugural corpus <- head(corpus, n = 10) corpus <- split_segments(corpus) #>   Splitting... #>   Done. tok <- tokens(corpus, remove_punct = TRUE) tok <- tokens_remove(tok, stopwords(\"en\")) dtm <- dfm(tok, tolower = TRUE) dtm <- dfm_trim(dtm, min_docfreq = 3) res <- rainette(dtm, k = 3, min_segment_size = 15) #>   Merging segments to comply with min_segment_size... #>   Clustering... #>   Done. rainette_plot(res, dtm)  # }"},{"path":"https://juba.github.io/rainette/reference/rainette_stats.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate cluster keyness statistics from a rainette result — rainette_stats","title":"Generate cluster keyness statistics from a rainette result — rainette_stats","text":"Generate cluster keyness statistics rainette result","code":""},{"path":"https://juba.github.io/rainette/reference/rainette_stats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate cluster keyness statistics from a rainette result — rainette_stats","text":"","code":"rainette_stats(   groups,   dtm,   measure = c(\"chi2\", \"lr\", \"frequency\", \"docprop\"),   n_terms = 15,   show_negative = TRUE,   max_p = 0.05 )"},{"path":"https://juba.github.io/rainette/reference/rainette_stats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate cluster keyness statistics from a rainette result — rainette_stats","text":"groups groups membership computed cutree_rainette cutree_rainette2 dtm dfm object used compute clustering measure statistics compute n_terms number terms display keyness plots show_negative TRUE, show negative keyness features max_p maximum keyness statistic p-value","code":""},{"path":"https://juba.github.io/rainette/reference/rainette_stats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate cluster keyness statistics from a rainette result — rainette_stats","text":"list , group, data.frame keyness statistics specific n_terms features.","code":""},{"path":[]},{"path":"https://juba.github.io/rainette/reference/rainette_stats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate cluster keyness statistics from a rainette result — rainette_stats","text":"","code":"# \\donttest{ require(quanteda) corpus <- data_corpus_inaugural corpus <- head(corpus, n = 10) corpus <- split_segments(corpus) #>   Splitting... #>   Done. tok <- tokens(corpus, remove_punct = TRUE) tok <- tokens_remove(tok, stopwords(\"en\")) dtm <- dfm(tok, tolower = TRUE) dtm <- dfm_trim(dtm, min_docfreq = 3) res <- rainette(dtm, k = 3, min_segment_size = 15) #>   Merging segments to comply with min_segment_size... #>   Clustering... #>   Done. groups <- cutree_rainette(res, k = 3) rainette_stats(groups, dtm) #> [[1]] #> # A tibble: 15 × 6 #>    feature     chi2           p n_target n_reference sign     #>    <chr>      <dbl>       <dbl>    <dbl>       <dbl> <fct>    #>  1 commerce    28.2 0.000000107       23           1 positive #>  2 states      26.3 0.000000290       49          18 positive #>  3 force       25.4 0.000000475       23           2 positive #>  4 revenue     21.9 0.00000294        16           0 positive #>  5 made        18.1 0.0000214         26           7 positive #>  6 shall      -16.5 0.0000479          4          35 negative #>  7 good       -15.1 0.000102           1          24 negative #>  8 powers      14.6 0.000134          20           5 positive #>  9 within      13.7 0.000215          16           3 positive #> 10 confidence -13.6 0.000222           1          22 negative #> 11 defense     13.3 0.000261          12           1 positive #> 12 naval       12.7 0.000358          11           0 positive #> 13 united      11.7 0.000614          32          16 positive #> 14 fellow     -11.5 0.000692           3          25 negative #> 15 war         11.4 0.000729          34          18 positive #>  #> [[2]] #> # A tibble: 15 × 6 #>    feature     chi2        p n_target n_reference sign     #>    <chr>      <dbl>    <dbl>    <dbl>       <dbl> <fct>    #>  1 shall       40.9 1.57e-10       28          11 positive #>  2 confidence  37.0 1.18e- 9       19           4 positive #>  3 high        21.6 3.39e- 6       14           5 positive #>  4 fellow      20.4 6.29e- 6       18          10 positive #>  5 duties      18.3 1.88e- 5       17          10 positive #>  6 station     17.5 2.94e- 5        9           1 positive #>  7 future      14.5 1.43e- 4       11           4 positive #>  8 good        14.3 1.56e- 4       15          10 positive #>  9 fervent     13.0 3.12e- 4        6           0 positive #> 10 indulgence  13.0 3.12e- 4        6           0 positive #> 11 presence    13.0 3.12e- 4        6           0 positive #> 12 states     -12.7 3.60e- 4        5          62 negative #> 13 conscious   10.3 1.34e- 3        5           0 positive #> 14 derive      10.3 1.34e- 3        5           0 positive #> 15 endeavor    10.3 1.34e- 3        5           0 positive #>  #> [[3]] #> # A tibble: 15 × 6 #>    feature      chi2          p n_target n_reference sign     #>    <chr>       <dbl>      <dbl>    <dbl>       <dbl> <fct>    #>  1 can         22.2  0.00000250       29          17 positive #>  2 happiness   20.4  0.00000617       15           4 positive #>  3 let         17.9  0.0000232        11           1 positive #>  4 truth       14.7  0.000125          8           0 positive #>  5 upon        14.4  0.000149         17           9 positive #>  6 man         13.6  0.000223          9           1 positive #>  7 government  13.3  0.000271         45          48 positive #>  8 order       12.7  0.000372         11           3 positive #>  9 republican  11.5  0.000690          8           1 positive #> 10 force      -11.3  0.000778          0          25 negative #> 11 love        11.0  0.000909          9           2 positive #> 12 made        -9.67 0.00188           2          31 negative #> 13 freedom      8.89 0.00286           9           3 positive #> 14 choice       8.13 0.00436           5           0 positive #> 15 false        8.13 0.00436           5           0 positive #>  # }"},{"path":"https://juba.github.io/rainette/reference/select_features.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove features from dtm of each group base don cc_test and tsj — select_features","title":"Remove features from dtm of each group base don cc_test and tsj — select_features","text":"Remove features dtm group base don cc_test tsj","code":""},{"path":"https://juba.github.io/rainette/reference/select_features.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove features from dtm of each group base don cc_test and tsj — select_features","text":"","code":"select_features(m, indices1, indices2, cc_test = 0.3, tsj = 3)"},{"path":"https://juba.github.io/rainette/reference/select_features.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove features from dtm of each group base don cc_test and tsj — select_features","text":"m global dtm indices1 indices documents group 1 indices2 indices documents group 2 cc_test maximum contingency coefficient value feature kept groups. tsj minimum feature frequency dtm","code":""},{"path":"https://juba.github.io/rainette/reference/select_features.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove features from dtm of each group base don cc_test and tsj — select_features","text":"list two character vectors : cols1 name features keep group 1, cols2 name features keep group 2","code":""},{"path":"https://juba.github.io/rainette/reference/select_features.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Remove features from dtm of each group base don cc_test and tsj — select_features","text":"Internal function, used directly","code":""},{"path":"https://juba.github.io/rainette/reference/split_segments.html","id":null,"dir":"Reference","previous_headings":"","what":"Split a character string or corpus into segments — split_segments","title":"Split a character string or corpus into segments — split_segments","text":"Split character string corpus segments, taking account punctuation possible","code":""},{"path":"https://juba.github.io/rainette/reference/split_segments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split a character string or corpus into segments — split_segments","text":"","code":"split_segments(obj, segment_size = 40, segment_size_window = NULL)  # S3 method for character split_segments(obj, segment_size = 40, segment_size_window = NULL)  # S3 method for Corpus split_segments(obj, segment_size = 40, segment_size_window = NULL)  # S3 method for corpus split_segments(obj, segment_size = 40, segment_size_window = NULL)  # S3 method for tokens split_segments(obj, segment_size = 40, segment_size_window = NULL)"},{"path":"https://juba.github.io/rainette/reference/split_segments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split a character string or corpus into segments — split_segments","text":"obj character string, quanteda tm corpus object segment_size segment size (words) segment_size_window window around segment size look best splitting point","code":""},{"path":"https://juba.github.io/rainette/reference/split_segments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split a character string or corpus into segments — split_segments","text":"obj tm quanteda corpus object, result quanteda corpus.","code":""},{"path":"https://juba.github.io/rainette/reference/split_segments.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Split a character string or corpus into segments — split_segments","text":"","code":"# \\donttest{ require(quanteda) split_segments(data_corpus_inaugural) #>   Splitting... #>   Done. #> Corpus consisting of 3,584 documents and 6 docvars. #> segment_source_1 : #> \"Fellow-Citizens of the Senate and of the House of Representa...\" #>  #> segment_source_2 : #> \"On the one hand, I was summoned by my Country, whose voice I...\" #>  #> segment_source_3 : #> \"as the asylum of my declining years - a retreat which was re...\" #>  #> segment_source_4 : #> \"On the other hand, the magnitude and difficulty of the trust...\" #>  #> segment_source_5 : #> \"could not but overwhelm with despondence one who (inheriting...\" #>  #> segment_source_6 : #> \"In this conflict of emotions all I dare aver is that it has ...\" #>  #> [ reached max_ndoc ... 3,578 more documents ] # }"},{"path":"https://juba.github.io/rainette/reference/switch_docs.html","id":null,"dir":"Reference","previous_headings":"","what":"Switch documents between two groups to maximize chi-square value — switch_docs","title":"Switch documents between two groups to maximize chi-square value — switch_docs","text":"Switch documents two groups maximize chi-square value","code":""},{"path":"https://juba.github.io/rainette/reference/switch_docs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Switch documents between two groups to maximize chi-square value — switch_docs","text":"","code":"switch_docs(m, indices, max_index, max_chisq)"},{"path":"https://juba.github.io/rainette/reference/switch_docs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Switch documents between two groups to maximize chi-square value — switch_docs","text":"m original dtm indices documents indices orderes first CA axis coordinates max_index document index split maximum max_chisq maximum chi-square value","code":""},{"path":"https://juba.github.io/rainette/reference/switch_docs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Switch documents between two groups to maximize chi-square value — switch_docs","text":"list two vectors indices1 indices2, contain documents indices group documents switching, chisq value, new corresponding chi-square value switching","code":""},{"path":"https://juba.github.io/rainette/reference/switch_docs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Switch documents between two groups to maximize chi-square value — switch_docs","text":"Internal function, used directly","code":""},{"path":"https://juba.github.io/rainette/news/index.html","id":"rainette-development-version","dir":"Changelog","previous_headings":"","what":"rainette (development version)","title":"rainette (development version)","text":"Replace call palette.colors() manual colors vector ensure compatibility R 3.6 (#11) Fix dendrogram displayed show_na_title = FALSE","code":""},{"path":"https://juba.github.io/rainette/news/index.html","id":"rainette-030","dir":"Changelog","previous_headings":"","what":"rainette 0.3.0","title":"rainette 0.3.0","text":"CRAN release: 2022-02-18","code":""},{"path":"https://juba.github.io/rainette/news/index.html","id":"new-features-0-3-0","dir":"Changelog","previous_headings":"","what":"New features","title":"rainette 0.3.0","text":"Rework double classification computation : New full argument rainette2(). TRUE (default, behavior previous versions), crossings groups two single classifications taken account find best partition. FALSE, crossings maximal associations kept. New parallel argument rainette2() compute partitions mclapply (FALSE default, won’t work Windows, uses RAM) Global optimization speed rainette2() computations, added progress bars better estimate long runs","code":""},{"path":"https://juba.github.io/rainette/news/index.html","id":"documentation-0-3-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"rainette 0.3.0","text":"Improved french vignette “description des algorithmes” New english vignette “algorithms description” Reworked french english introduction vignettes","code":""},{"path":"https://juba.github.io/rainette/news/index.html","id":"deprecated-features-0-3-0","dir":"Changelog","previous_headings":"","what":"Deprecated features","title":"rainette 0.3.0","text":"wordcloud plots deprecated near future. warning added rainette_plot() rainette2_plot() called type = \"cloud\".","code":""},{"path":"https://juba.github.io/rainette/news/index.html","id":"other-0-3-0","dir":"Changelog","previous_headings":"","what":"Other","title":"rainette 0.3.0","text":"Add show_na_title, cluster_label keyness_plot_xlab arguments rainette_plot() customize graphics output Fix warnings Font Awesome icon names","code":""},{"path":"https://juba.github.io/rainette/news/index.html","id":"rainette-021","dir":"Changelog","previous_headings":"","what":"rainette 0.2.1","title":"rainette 0.2.1","text":"CRAN release: 2021-10-06 Add option show merged segments document browser Fix warning error rainette_explor rainette2_explor cluster dfm empty Fix error dfm contains empty string feature","code":""},{"path":"https://juba.github.io/rainette/news/index.html","id":"rainette-020","dir":"Changelog","previous_headings":"","what":"rainette 0.2.0","title":"rainette 0.2.0","text":"CRAN release: 2021-06-25","code":""},{"path":"https://juba.github.io/rainette/news/index.html","id":"important-and-breaking-changes-0-2-0","dir":"Changelog","previous_headings":"","what":"Important and breaking changes","title":"rainette 0.2.0","text":"min_uc_size, uc_size1 uc_size2 arguments rainette rainette2 renamed min_segment_size, min_segment_size1 min_segment_size2. default value min_segment_size rainette now 0, means merging done segments default. Results different previous package versions min_uc_size specified. Important bugfix : merging segments based min_segment_size handled correctly previous versions regarding segment sources, segments different documents merged together. now fixed.","code":""},{"path":"https://juba.github.io/rainette/news/index.html","id":"new-features-0-2-0","dir":"Changelog","previous_headings":"","what":"New features","title":"rainette 0.2.0","text":"new graphical interface browse cluster documents added rainette_explor rainette2_explor. New function clusters_by_doc_table gives number segments cluster document. New function docs_by_cluster_table gives, cluster, number documents least one segment cluster. split_segments now 4 times faster. Terms frequencies documents proportions statistics added explor interfaces.","code":""},{"path":"https://juba.github.io/rainette/news/index.html","id":"other-0-2-0","dir":"Changelog","previous_headings":"","what":"Other","title":"rainette 0.2.0","text":"rainette called min_segment_size > 0, doc_id argument must given name dtm docvar identifying segments source. corpus produced split_segments, added segment_source docvar used default. Color palette clusters changed “Tableau 10”. Negative keyness values shown default anymore rainette_explor, rainette2_explor, rainette_plot rainette2_plot. Wordcloud plots removed explor interfaces. warning displayed min_split_members < 3. rainette_explor called rainette2 results object, rainette2_explor launched automatically.","code":""},{"path":"https://juba.github.io/rainette/news/index.html","id":"rainette-013","dir":"Changelog","previous_headings":"","what":"rainette 0.1.3","title":"rainette 0.1.3","text":"CRAN release: 2021-05-11 Parallel computing split_segments removed Fix potential name conflicts rainette_explor Compatibility quanteda v3 (thanks @kbenoit)","code":""},{"path":"https://juba.github.io/rainette/news/index.html","id":"rainette-012","dir":"Changelog","previous_headings":"","what":"rainette 0.1.2","title":"rainette 0.1.2","text":"CRAN release: 2021-01-20 Fix bug due factor comparison rainette2","code":""},{"path":"https://juba.github.io/rainette/news/index.html","id":"rainette-011","dir":"Changelog","previous_headings":"","what":"rainette 0.1.1","title":"rainette 0.1.1","text":"CRAN release: 2020-05-09 Compatibility dplyr 1.0 Fix bug p threshold rainette_stats","code":""},{"path":"https://juba.github.io/rainette/news/index.html","id":"rainette-010","dir":"Changelog","previous_headings":"","what":"rainette 0.1.0","title":"rainette 0.1.0","text":"First version","code":""}]
